{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality = pd.read_parquet(\"../data_deliveries/2_all_data_air_quality_from_2018.parquet\")\n",
    "df_air_quality_locations = pd.read_excel(\"../../data/info/calidad_del_aire/informacion_estaciones_red_calidad_aire.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_locations = df_air_quality_locations.drop(columns = ['SO2','CO','PM10','PM2_5','O3','BTX','Fecha alta','VIA_CLASE','VIA_PAR','VIA_NOMBRE','LONGITUD_ETRS89','LATITUD_ETRS89','COORDENADA_X_ETRS89','COORDENADA_Y_ETRS89','NO2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality = df_air_quality[df_air_quality['MAGNITUD'] == 8]\n",
    "df_air_quality['CODIGO'] = df_air_quality['PUNTO_MUESTREO'].str.split('_').str[0]\n",
    "df_air_quality['CODIGO'] = df_air_quality['CODIGO'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_locations = df_air_quality_locations.rename(columns={'ESTACION':'LOCALIZACION'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código realiza los siguientes pasos:\n",
    "\n",
    "- Iteración sobre cada fila: Se procesan todas las filas del DataFrame original.\n",
    "- Extracción de datos por hora: Para cada fila, se crea una nueva fila para cada hora (de 1 a 24), asignando los valores correspondientes de las columnas Hxx y Vxx.\n",
    "- Construcción del nuevo DataFrame: Se utiliza una lista de diccionarios para crear un DataFrame transformado.\n",
    "- Ordenación y limpieza: Se ordena el DataFrame por columnas clave y se reinician los índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tu DataFrame original se llama `df`\n",
    "# Creamos una lista para almacenar las filas transformadas\n",
    "rows = []\n",
    "\n",
    "# Iteramos sobre cada fila del DataFrame original\n",
    "for _, row in df_air_quality.iterrows():\n",
    "    for hour in range(1, 25):  # De la hora 1 a la 24\n",
    "        # Construimos un diccionario para la nueva fila\n",
    "        new_row = {\n",
    "            'CODIGO': row['CODIGO'],\n",
    "            'PROVINCIA': row['PROVINCIA'],\n",
    "            'MUNICIPIO': row['MUNICIPIO'],\n",
    "            'ESTACION': row['ESTACION'],\n",
    "            'MAGNITUD': row['MAGNITUD'],\n",
    "            'PUNTO_MUESTREO': row['PUNTO_MUESTREO'],\n",
    "            'ANO': row['ANO'],\n",
    "            'MES': row['MES'],\n",
    "            'DIA': row['DIA'],\n",
    "            'HORA': hour,  # Agregamos la hora\n",
    "            'VALOR': row[f'H{hour:02}'],  # Obtenemos el valor de la columna Hxx\n",
    "            'VALIDACION': row[f'V{hour:02}'],  # Obtenemos el valor de la columna Vxx\n",
    "        }\n",
    "        rows.append(new_row)  # Añadimos la nueva fila a la lista\n",
    "\n",
    "# Creamos un nuevo DataFrame a partir de las filas transformadas\n",
    "df_transformado = pd.DataFrame(rows)\n",
    "\n",
    "# Creamos una nueva columna de fecha\n",
    "df_transformado['FECHA'] = pd.to_datetime(df_transformado[['ANO', 'MES', 'DIA', 'HORA']].rename(columns={'ANO': 'year', 'MES': 'month', 'DIA': 'day', 'HORA': 'hour'}))\n",
    "df_transformado = df_transformado.rename(columns = {'VALOR': 'NO2_VALUE', 'ANO': 'YEAR', 'MES': 'MONTH', 'DIA': 'DAY', 'HORA': 'HOUR'})\n",
    "# Opcional: ordenamos por las columnas clave para facilitar el análisis\n",
    "df_transformado = df_transformado.sort_values(by=['CODIGO','PROVINCIA', 'MUNICIPIO', 'ESTACION', 'YEAR', 'MONTH', 'DAY', 'HOUR'])\n",
    "\n",
    "# Reiniciamos los índices para el nuevo DataFrame\n",
    "df_transformado.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformado = df_transformado[df_transformado['VALIDACION'] == 'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_and_locations = pd.merge(df_transformado, df_air_quality_locations, left_on='CODIGO', right_on='CODIGO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_and_locations.to_parquet(\"df_air_quality_and_locations_from_2018.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
