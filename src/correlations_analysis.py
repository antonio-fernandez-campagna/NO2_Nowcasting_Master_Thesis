"""
M√≥dulo refactorizado para an√°lisis de relaci√≥n entre sensores de NO2 y tr√°fico en Madrid.

Este m√≥dulo proporciona una interfaz integrada para analizar correlaciones entre
datos de contaminaci√≥n por NO2, tr√°fico y variables meteorol√≥gicas.
"""

import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import numpy as np
from datetime import timedelta
import seaborn as sns
import altair as alt
from typing import Dict, List, Optional, Tuple
import warnings

warnings.filterwarnings('ignore')


# ==================== CONFIGURACI√ìN Y CONSTANTES ====================

GRANULARITY_CONFIG = {
    'Horaria': {'freq': 'H', 'format': '%Y-%m-%d %H:%M'},
    'Diaria': {'freq': 'D', 'format': '%Y-%m-%d'},
    'Semanal': {'freq': 'W', 'format': '%Y-%m-%d'},
    'Mensual': {'freq': 'M', 'format': '%Y-%m'}
}

VARIABLE_COLORS = ['#E41A1C', '#BC1AE4', '#4DAF4A', '#984EA3', '#FF7F00', '#FFFF33']

TRAFFIC_VARIABLES = ['intensidad', 'carga', 'ocupacion',
                     'intensidad_lag1', 'intensidad_lag2', 'intensidad_lag3', 'intensidad_lag4', 'intensidad_lag6', 'intensidad_lag8',
                     'ocupacion_lag1', 'ocupacion_lag2', 'ocupacion_lag3', 'ocupacion_lag4', 'ocupacion_lag6', 'ocupacion_lag8',
                     'carga_lag1', 'carga_lag2', 'carga_lag3', 'carga_lag4', 'carga_lag6', 'carga_lag8']
METEO_VARIABLES = ['d2m', 't2m', 'sst', 'ssrd', 'u10', 'v10', 'sp', 'tp', 
                   'wind_speed', 'wind_direction_deg', 'wind_dir_sin', 'wind_dir_cos']

VARIABLE_LABELS = {
    # Tr√°fico
    'intensidad': 'Intensidad de tr√°fico (veh/h)',
    'carga': 'Carga de tr√°fico (%)',
    'ocupacion': 'Ocupaci√≥n vial (%)',

    # Lags de intensidad
    'intensidad_lag1': 'Intensidad de tr√°fico (t‚àí1h)',
    'intensidad_lag2': 'Intensidad de tr√°fico (t‚àí2h)',
    'intensidad_lag3': 'Intensidad de tr√°fico (t‚àí3h)',
    'intensidad_lag4': 'Intensidad de tr√°fico (t‚àí4h)',
    'intensidad_lag6': 'Intensidad de tr√°fico (t‚àí6h)',
    'intensidad_lag8': 'Intensidad de tr√°fico (t‚àí8h)',

    # Lags de ocupaci√≥n
    'ocupacion_lag1': 'Ocupaci√≥n vial (t‚àí1h)',
    'ocupacion_lag2': 'Ocupaci√≥n vial (t‚àí2h)',
    'ocupacion_lag3': 'Ocupaci√≥n vial (t‚àí3h)',
    'ocupacion_lag4': 'Ocupaci√≥n vial (t‚àí4h)',
    'ocupacion_lag6': 'Ocupaci√≥n vial (t‚àí6h)',
    'ocupacion_lag8': 'Ocupaci√≥n vial (t‚àí8h)',

    # Lags de carga
    'carga_lag1': 'Carga de tr√°fico (t‚àí1h)',
    'carga_lag2': 'Carga de tr√°fico (t‚àí2h)',
    'carga_lag3': 'Carga de tr√°fico (t‚àí3h)',
    'carga_lag4': 'Carga de tr√°fico (t‚àí4h)',
    'carga_lag6': 'Carga de tr√°fico (t‚àí6h)',
    'carga_lag8': 'Carga de tr√°fico (t‚àí8h)',

    # Meteorolog√≠a
    'd2m': 'Punto de roc√≠o (¬∞C)',
    't2m': 'Temperatura a 2‚ÄØm (¬∞C)',
    'ssrd': 'Radiaci√≥n solar (kWh/m¬≤)',
    'ssr': 'Radiaci√≥n neta (kWh/m¬≤)',
    'u10': 'Componente U del viento (km/h)',
    'v10': 'Componente V del viento (km/h)',
    'wind_speed': 'Velocidad del viento (km/h)',
    'wind_direction_deg': 'Direcci√≥n del viento (¬∞)',
    'wind_dir_sin': 'Direcci√≥n del viento (sin)',
    'wind_dir_cos': 'Direcci√≥n del viento (cos)',
    'sp': 'Presi√≥n superficial (hPa)',
    'tp': 'Precipitaci√≥n acumulada (mm)',
}



# ==================== CLASE PRINCIPAL ====================

class SensorAnalyzer:
    """Clase principal para an√°lisis de sensores de NO2 y tr√°fico."""
    
    def __init__(self):
        self.df_master = None
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Inicializa el estado de la sesi√≥n."""
        if 'sensor_data_loaded' not in st.session_state:
            st.session_state.sensor_data_loaded = False
        if 'sensor_config' not in st.session_state:
            st.session_state.sensor_config = {}
    
    @st.cache_data(ttl=3600)
    def load_data(_self) -> pd.DataFrame:
        """Carga y preprocesa los datos de sensores con cach√©."""
        try:
            df = pd.read_parquet('data/super_processed/7_4_no2_with_traffic_and_1meteo_and_1trafic_id.parquet')
            df['fecha'] = pd.to_datetime(df['fecha'])
            return df
        except Exception as e:
            st.error(f"Error al cargar los datos: {str(e)}")
            return pd.DataFrame()
    
    def filter_and_aggregate_data(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """Filtra y agrega los datos seg√∫n la configuraci√≥n."""
        # Filtrar por sensor y fechas
        df_filtered = df[
            (df["id_no2"] == config['sensor']) & 
            (df["fecha"].dt.date >= config['fecha_inicio']) & 
            (df["fecha"].dt.date <= config['fecha_fin'])
        ].copy()
        
        # Filtrar por sensor de tr√°fico si est√° especificado
        if config.get('sensor_trafico'):
            df_filtered = df_filtered[df_filtered["id_trafico"] == config['sensor_trafico']]
        
        # Aplicar granularidad temporal
        granularity = config['granularity']
        freq = GRANULARITY_CONFIG[granularity]['freq']
        
        if granularity == "Horaria":
            df_filtered["time_group"] = df_filtered["fecha"].dt.floor(freq)
            df_aggregated = df_filtered.copy()
        else:
            if granularity in ["Semanal", "Mensual"]:
                df_filtered["time_group"] = df_filtered["fecha"].dt.to_period(freq).dt.to_timestamp()
            else:
                df_filtered["time_group"] = df_filtered["fecha"].dt.floor(freq)
            
            # Agregar datos
            agg_vars = ["no2_value"] + config['variables']
            df_aggregated = df_filtered.groupby("time_group").agg({
                var: "mean" for var in agg_vars
            }).reset_index()
        
        return df_aggregated
    
    def create_time_series_plot(self, df: pd.DataFrame, variable: str, color: str) -> plt.Figure:
        """Genera un gr√°fico de series temporales con dos ejes."""
        fig, ax1 = plt.subplots(figsize=(12, 4))
        
        # Eje NO2
        ax1.set_xlabel('Fecha')
        ax1.set_ylabel('NO‚ÇÇ (Œºg/m¬≥)', color='tab:blue')
        ax1.plot(df['time_group'], df['no2_value'],
                 color='tab:blue', marker='o', label='NO‚ÇÇ', linewidth=2)
        ax1.tick_params(axis='y', labelcolor='tab:blue')
        #ax1.axhline(y=40, color='r', linestyle='--', alpha=0.7, label='L√≠mite OMS')
        
        # Eje variable
        ax2 = ax1.twinx()
        variable_label = VARIABLE_LABELS.get(variable, variable.capitalize())
        ax2.set_ylabel(variable_label, color=color)
        ax2.plot(df['time_group'], df[variable],
                 color=color, marker='x', label=variable, linewidth=2)
        ax2.tick_params(axis='y', labelcolor=color)
        
        # Formateo
        fig.autofmt_xdate()
        plt.title(f'Comparativa NO‚ÇÇ vs {variable_label}', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        return fig
    
    def create_scatter_plot(self, df: pd.DataFrame, variable: str, color: str) -> plt.Figure:
        """Genera un scatter plot con l√≠nea de regresi√≥n."""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Calcular correlaci√≥n
        correlation = df[variable].corr(df['no2_value'])
        
        # Crear scatter plot
        sns.scatterplot(x=df[variable], y=df['no2_value'], color=color, ax=ax, alpha=0.7)
        sns.regplot(x=df[variable], y=df['no2_value'], 
                   scatter=False, color=color, ax=ax, line_kws={'linewidth': 2})
        
        # Formateo
        variable_label = VARIABLE_LABELS.get(variable, variable.capitalize())
        plt.title(f'{variable_label} vs NO‚ÇÇ\nCorrelaci√≥n: {correlation:.3f}', 
                 fontsize=14, fontweight='bold')
        plt.xlabel(variable_label)
        plt.ylabel('NO‚ÇÇ (Œºg/m¬≥)')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        return fig
    
    def create_altair_scatter(self, df: pd.DataFrame, variable: str, color: str) -> alt.Chart:
        """Genera un gr√°fico interactivo de dispersi√≥n con Altair."""
        variable_label = VARIABLE_LABELS.get(variable, variable.capitalize())
        
        scatter_chart = alt.Chart(df).mark_circle(size=60, opacity=0.7).encode(
            x=alt.X(variable, title=variable_label),
            y=alt.Y('no2_value', title='NO‚ÇÇ (Œºg/m¬≥)'),
            tooltip=[
                alt.Tooltip(variable, title=variable_label, format='.2f'),
                alt.Tooltip('no2_value', title='NO‚ÇÇ', format='.2f'),
                alt.Tooltip('time_group', title='Fecha')
            ]
        ).properties(width=400, height=300)
        
        regression = scatter_chart.transform_regression(
            variable, 'no2_value'
        ).mark_line(color=color, strokeDash=[4, 2], size=2)
        
        return (scatter_chart + regression).resolve_scale(color='independent')
    
    def create_correlation_matrix(self, df: pd.DataFrame, variables: List[str]) -> plt.Figure:
        """Muestra una matriz de correlaci√≥n entre las variables seleccionadas."""
        cols = ["no2_value"] + variables
        corr_data = df[cols].corr()
        
        # Renombrar columnas para mejor visualizaci√≥n
        rename_dict = {var: VARIABLE_LABELS.get(var, var.capitalize()) for var in variables}
        rename_dict['no2_value'] = 'NO‚ÇÇ'
        corr_data = corr_data.rename(index=rename_dict, columns=rename_dict)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        mask = np.triu(np.ones_like(corr_data, dtype=bool))
        cmap = sns.diverging_palette(230, 20, as_cmap=True)
        
        sns.heatmap(corr_data, mask=mask, cmap=cmap, annot=True, fmt=".3f",
                   square=True, linewidths=.5, ax=ax, cbar_kws={'label': 'Correlaci√≥n'})
        plt.title('Matriz de Correlaci√≥n: NO‚ÇÇ vs Variables Seleccionadas', 
                 fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        return fig
    
    def analyze_data_availability(self, df_filtered: pd.DataFrame) -> Dict:
        """Analiza y calcula m√©tricas de disponibilidad de datos."""
        if df_filtered.empty:
            return {}
        
        fecha_min = df_filtered["fecha"].min()
        fecha_max = df_filtered["fecha"].max()
        
        # Generar rango completo de horas
        todas_horas = pd.date_range(
            start=fecha_min.replace(hour=0, minute=0, second=0),
            end=fecha_max.replace(hour=23, minute=59, second=59),
            freq='H'
        )
        
        # Crear DataFrame completo y marcar datos disponibles
        df_completo = pd.DataFrame(index=todas_horas)
        df_completo.index.name = 'hora'
        df_filtrado_hora = df_filtered.set_index("fecha")
        df_completo['tiene_datos'] = df_completo.index.isin(df_filtrado_hora.index).astype(int)
        
        # Calcular m√©tricas
        total_horas = len(todas_horas)
        horas_con_datos = df_completo['tiene_datos'].sum()
        porcentaje_completitud = (horas_con_datos / total_horas) * 100
        
        # Disponibilidad por hora del d√≠a y d√≠a de la semana
        df_completo['dia_semana'] = df_completo.index.dayofweek
        pivot_data = df_completo.pivot_table(
            values='tiene_datos', 
            index=df_completo.index.hour,
            columns='dia_semana', 
            aggfunc='mean'
        ) * 100
        
        return {
            'total_horas': total_horas,
            'horas_con_datos': horas_con_datos,
            'porcentaje_completitud': porcentaje_completitud,
            'pivot_data': pivot_data,
            'fecha_inicio': fecha_min,
            'fecha_fin': fecha_max
        }


# ==================== FUNCIONES DE VISUALIZACI√ìN ====================

def show_availability_analysis(disponibilidad: Dict):
    """Renderiza las m√©tricas y gr√°ficos de disponibilidad."""
    if not disponibilidad:
        st.warning("No hay datos suficientes para analizar la disponibilidad.")
        return
    
    st.subheader("üìä An√°lisis de disponibilidad de datos")
    
    # M√©tricas principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Total de horas", 
            f"{disponibilidad['total_horas']:,}",
            help="N√∫mero total de horas en el per√≠odo seleccionado"
        )
    
    with col2:
        st.metric(
            "Horas con datos", 
            f"{disponibilidad['horas_con_datos']:,}",
            help="N√∫mero de horas con datos disponibles"
        )
    
    with col3:
        st.metric(
            "Completitud", 
            f"{disponibilidad['porcentaje_completitud']:.1f}%",
            help="Porcentaje de datos disponibles"
        )
    
    with col4:
        horas_faltantes = disponibilidad['total_horas'] - disponibilidad['horas_con_datos']
        st.metric(
            "Datos faltantes", 
            f"{horas_faltantes:,}",
            delta=f"-{100-disponibilidad['porcentaje_completitud']:.1f}%",
            delta_color="inverse",
            help="N√∫mero de horas sin datos"
        )
    
    # Heatmap de disponibilidad
    st.subheader("Patr√≥n de disponibilidad por hora y d√≠a")
    
    dias_semana = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']
    fig, ax = plt.subplots(figsize=(12, 8))
    
    sns.heatmap(
        disponibilidad['pivot_data'], 
        annot=False, 
        cmap='RdYlGn', 
        vmin=0, 
        vmax=100, 
        xticklabels=dias_semana, 
        yticklabels=range(24),
        cbar_kws={'label': 'Disponibilidad (%)'},
        ax=ax
    )
    
    plt.title('Disponibilidad de datos por hora del d√≠a y d√≠a de la semana', 
             fontsize=14, fontweight='bold')
    plt.xlabel('D√≠a de la semana')
    plt.ylabel('Hora del d√≠a')
    plt.tight_layout()
    
    st.pyplot(fig)
    
    # Informaci√≥n adicional
    with st.expander("‚ÑπÔ∏è Interpretaci√≥n del an√°lisis de disponibilidad"):
        st.markdown("""
        **¬øC√≥mo interpretar este an√°lisis?**
        
        - **Verde intenso**: Alta disponibilidad de datos (>80%)
        - **Amarillo**: Disponibilidad moderada (40-80%)
        - **Rojo**: Baja disponibilidad de datos (<40%)
        
        **Patrones comunes:**
        - Los sensores pueden tener mantenimiento programado en ciertas horas
        - Algunos d√≠as de la semana pueden tener menos cobertura
        - Las interrupciones pueden indicar problemas t√©cnicos o climatol√≥gicos
        """)


def show_info_panel():
    """Muestra panel de informaci√≥n sobre el an√°lisis de sensores."""
    with st.expander("‚ÑπÔ∏è Acerca de este an√°lisis", expanded=False):
        st.markdown("""
        **An√°lisis de Sensores: Tr√°fico y NO‚ÇÇ**
        
        Este m√≥dulo permite analizar la relaci√≥n entre los datos de tr√°fico, variables meteorol√≥gicas 
        y los niveles de NO‚ÇÇ en Madrid.
        
        **Funcionalidades:**
        - An√°lisis de correlaciones entre NO‚ÇÇ y m√∫ltiples variables
        - Visualizaci√≥n de series temporales comparativas
        - Gr√°ficos de dispersi√≥n con l√≠neas de regresi√≥n
        - An√°lisis de disponibilidad temporal de datos
        - Matrices de correlaci√≥n interactivas
        
        **Variables disponibles:**
        - **Tr√°fico**: Intensidad, carga, ocupaci√≥n
        - **Meteorol√≥gicas**: Temperatura, humedad, presi√≥n, viento, precipitaci√≥n
        
        **Granularidades temporales:**
        - Horaria, diaria, semanal y mensual
        """)


# ==================== FUNCIONES DE CONFIGURACI√ìN EN P√ÅGINA ====================

def create_page_configuration(analyzer) -> Dict:
    """Crea los controles de configuraci√≥n directamente en la p√°gina principal."""
    st.subheader("Configuraci√≥n del an√°lisis")
    
    # Dividir en columnas para mejor organizaci√≥n
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("##### üî¨ Selecci√≥n de sensores")
        
        # Selecci√≥n de sensores
        sensores = sorted(analyzer.df_master["id_no2"].unique())
        sensor_seleccionado = st.selectbox("Sensor de NO‚ÇÇ", sensores, index=0)
        
        # Sensor de tr√°fico asociado
        sensores_trafico = sorted(analyzer.df_master[
            analyzer.df_master["id_no2"] == sensor_seleccionado
        ]["id_trafico"].unique())
        
        if sensores_trafico:
            sensor_trafico = st.selectbox(
                "Sensor de tr√°fico asociado", 
                sensores_trafico, 
                disabled=True,
                help="Sensor de tr√°fico m√°s cercano al sensor de NO‚ÇÇ seleccionado"
            )
        else:
            sensor_trafico = None
            st.warning("No hay sensores de tr√°fico asociados")
    
    with col2:
        st.markdown("##### üìÖ Filtros temporales")
        
        # Filtros de fecha
        fecha_min = analyzer.df_master["fecha"].min().date()
        fecha_max = analyzer.df_master["fecha"].max().date()
        
        fecha_inicio = st.date_input(
            "Fecha inicial", 
            fecha_min, 
            min_value=fecha_min, 
            max_value=fecha_max
        )
        
        fecha_fin = st.date_input(
            "Fecha final", 
            fecha_max, 
            min_value=fecha_min, 
            max_value=fecha_max
        )
        
        if fecha_inicio > fecha_fin:
            st.error("La fecha inicial debe ser anterior a la final.")
            fecha_fin = fecha_inicio + timedelta(days=7)
        
        # Granularidad temporal
        granularity = st.selectbox(
            "Granularidad temporal", 
            list(GRANULARITY_CONFIG.keys()),
            index=3  # Mensual por defecto
        )
    
    with col3:
        st.markdown("##### üìä Variables de an√°lisis")
        
        # Selecci√≥n de variables
        variables_disponibles = TRAFFIC_VARIABLES + METEO_VARIABLES
        variables_disponibles = [
            var for var in variables_disponibles 
            if var in analyzer.df_master.columns
        ]
        
        variables_seleccionadas = st.multiselect(
            "Variables a analizar", 
            variables_disponibles, 
            default=variables_disponibles[:4],
            help="Selecciona las variables que quieres comparar con NO‚ÇÇ"
        )
    
    return {
        'sensor': sensor_seleccionado,
        'sensor_trafico': sensor_trafico,
        'fecha_inicio': fecha_inicio,
        'fecha_fin': fecha_fin,
        'granularity': granularity,
        'variables': variables_seleccionadas
    }


# ==================== FUNCI√ìN PRINCIPAL ====================

def analisis_sensores():
    """Funci√≥n principal del an√°lisis de sensores."""
    
    st.title("An√°lisis de Sensores: Tr√°fico y NO‚ÇÇ")
    st.markdown("An√°lisis de la relaci√≥n entre los datos de tr√°fico, variables meteorol√≥gicas y los niveles de NO‚ÇÇ en Madrid")
    
    # Inicializar analizador
    analyzer = SensorAnalyzer()
    
    # Panel de informaci√≥n
    show_info_panel()
    
    # Cargar datos
    if not st.session_state.sensor_data_loaded:
        if st.button("Cargar datos de sensores", type="primary"):
            with st.spinner("Cargando datos de sensores y tr√°fico..."):
                analyzer.df_master = analyzer.load_data()
                if not analyzer.df_master.empty:
                    st.session_state.sensor_data_loaded = True
                    st.success("Datos cargados correctamente!")
                    st.rerun()
        return
    
    # Recuperar datos
    analyzer.df_master = analyzer.load_data()
    
    if analyzer.df_master.empty:
        st.error("No se pudieron cargar los datos.")
        return
    
    # Configuraci√≥n en la p√°gina principal
    config = create_page_configuration(analyzer)
    
    # Separador visual
    st.markdown("---")
    
    if not config['variables']:
        st.warning("üëÜ Selecciona al menos una variable en la secci√≥n de configuraci√≥n para continuar.")
        return
    
    # Procesar datos
    with st.spinner("Procesando datos..."):
        df_aggregated = analyzer.filter_and_aggregate_data(analyzer.df_master, config)
    
    if df_aggregated.empty:
        st.error("No hay datos disponibles para los filtros seleccionados.")
        return
    
    # Mostrar informaci√≥n del conjunto de datos
    st.header(f"An√°lisis del sensor {config['sensor']}")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Per√≠odos analizados", len(df_aggregated))
    with col2:
        st.metric("NO‚ÇÇ promedio", f"{df_aggregated['no2_value'].mean():.1f} Œºg/m¬≥")
    with col3:
        st.metric("NO‚ÇÇ m√°ximo", f"{df_aggregated['no2_value'].max():.1f} Œºg/m¬≥")
    with col4:
        dias_analisis = (config['fecha_fin'] - config['fecha_inicio']).days + 1
        st.metric("D√≠as de an√°lisis", dias_analisis)
    
    # Tabs de visualizaci√≥n
    tab1, tab2, tab3 = st.tabs([
        "An√°lisis temporal", 
        "Correlaciones", 
        "Disponibilidad de datos"
    ])
    
    # Tab 1: An√°lisis temporal
    with tab1:
        st.subheader("Series temporales de NO‚ÇÇ y variables seleccionadas")
        
        # Organizar gr√°ficos en dos columnas
        for i in range(0, len(config['variables']), 2):
            col1, col2 = st.columns(2)
            
            with col1:
                variable = config['variables'][i]
                color = VARIABLE_COLORS[i % len(VARIABLE_COLORS)]
                fig = analyzer.create_time_series_plot(df_aggregated, variable, color)
                st.pyplot(fig)
            
            if i + 1 < len(config['variables']):
                with col2:
                    variable = config['variables'][i + 1]
                    color = VARIABLE_COLORS[(i + 1) % len(VARIABLE_COLORS)]
                    fig = analyzer.create_time_series_plot(df_aggregated, variable, color)
                    st.pyplot(fig)
    
    # Tab 2: Correlaciones
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Matriz de correlaci√≥n")
            fig_corr = analyzer.create_correlation_matrix(df_aggregated, config['variables'])
            st.pyplot(fig_corr)
        
        with col2:
            st.subheader("Estad√≠sticas de correlaci√≥n")
            
            # Tabla de correlaciones
            correlations = []
            for var in config['variables']:
                corr = df_aggregated[var].corr(df_aggregated['no2_value'])
                correlations.append({
                    'Variable': VARIABLE_LABELS.get(var, var.capitalize()),
                    'Correlaci√≥n': corr,
                    'Interpretaci√≥n': 'Fuerte' if abs(corr) > 0.7 else 'Moderada' if abs(corr) > 0.3 else 'D√©bil'
                })
            
            df_corr = pd.DataFrame(correlations)
            st.dataframe(df_corr, use_container_width=True)
        
        # Subtabs para gr√°ficos de dispersi√≥n
        scatter_tab1, scatter_tab2 = st.tabs(["Gr√°ficos est√°ticos", "Gr√°ficos interactivos"])
        
        with scatter_tab1:
            st.subheader("Gr√°ficos de dispersi√≥n con regresi√≥n")
            for i in range(0, len(config['variables']), 2):
                col1, col2 = st.columns(2)
                
                with col1:
                    variable = config['variables'][i]
                    color = VARIABLE_COLORS[i % len(VARIABLE_COLORS)]
                    fig = analyzer.create_scatter_plot(df_aggregated, variable, color)
                    st.pyplot(fig)
                
                if i + 1 < len(config['variables']):
                    with col2:
                        variable = config['variables'][i + 1]
                        color = VARIABLE_COLORS[(i + 1) % len(VARIABLE_COLORS)]
                        fig = analyzer.create_scatter_plot(df_aggregated, variable, color)
                        st.pyplot(fig)
        
        with scatter_tab2:
            st.subheader("Gr√°ficos interactivos de dispersi√≥n")
            for i in range(0, len(config['variables']), 2):
                col1, col2 = st.columns(2)
                
                with col1:
                    variable = config['variables'][i]
                    color = VARIABLE_COLORS[i % len(VARIABLE_COLORS)]
                    chart = analyzer.create_altair_scatter(df_aggregated, variable, color)
                    st.altair_chart(chart, use_container_width=True)
                
                if i + 1 < len(config['variables']):
                    with col2:
                        variable = config['variables'][i + 1]
                        color = VARIABLE_COLORS[(i + 1) % len(VARIABLE_COLORS)]
                        chart = analyzer.create_altair_scatter(df_aggregated, variable, color)
                        st.altair_chart(chart, use_container_width=True)
    
    # Tab 3: Disponibilidad de datos
    with tab3:
        # Necesitamos los datos originales filtrados para el an√°lisis de disponibilidad
        df_original_filtered = analyzer.df_master[
            (analyzer.df_master["id_no2"] == config['sensor']) & 
            (analyzer.df_master["fecha"].dt.date >= config['fecha_inicio']) & 
            (analyzer.df_master["fecha"].dt.date <= config['fecha_fin'])
        ].copy()
        
        if config['sensor_trafico']:
            df_original_filtered = df_original_filtered[
                df_original_filtered["id_trafico"] == config['sensor_trafico']
            ]
        
        disponibilidad = analyzer.analyze_data_availability(df_original_filtered)
        show_availability_analysis(disponibilidad)
    
    # Pie de p√°gina
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: #666; font-size: 0.8rem;">
        An√°lisis de sensor {config['sensor']} | Per√≠odo: {config['fecha_inicio'].strftime('%d/%m/%Y')} - {config['fecha_fin'].strftime('%d/%m/%Y')}
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    analisis_sensores() 