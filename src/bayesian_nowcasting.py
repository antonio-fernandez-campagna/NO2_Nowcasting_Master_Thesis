"""
M√≥dulo de Nowcasting Bayesiano para predicci√≥n de NO‚ÇÇ con cuantificaci√≥n de incertidumbre.

Este m√≥dulo implementa redes neuronales bayesianas usando TensorFlow Probability para
predecir niveles de NO‚ÇÇ con estimaciones de incertidumbre mediante muestreo Monte Carlo.
"""

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import tensorflow as tf
import tensorflow_probability as tfp
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from datetime import datetime, timedelta
import time
import warnings
from typing import Dict, List, Tuple, Optional
import joblib
import os

warnings.filterwarnings('ignore')
tf.get_logger().setLevel('ERROR')

# Configurar TensorFlow para usar la GPU si est√° disponible
tf.config.experimental.enable_memory_growth = True

# Distribuciones de TensorFlow Probability
tfd = tfp.distributions
tfpl = tfp.layers

# Importar configuraciones centralizadas
from src.config import (
    OUTLIER_METHODS, PREPROCESSING_OPTIONS, VARIABLE_CATEGORIES, 
    VARIABLE_METADATA, COLUMNS_FOR_OUTLIERS
)


# ==================== CONFIGURACI√ìN Y CONSTANTES ====================

# Configuraciones de modelo predefinidas
MODEL_CONFIGS = {
    'simple': {
        'name': 'Simple (2 capas)',
        'layers': [64, 32],
        'dropout': 0.2,
        'description': 'Modelo b√°sico con 2 capas densas'
    },
    'medium': {
        'name': 'Medio (3 capas)',
        'layers': [128, 64, 32],
        'dropout': 0.25,
        'description': 'Modelo intermedio con 3 capas densas'
    },
    'deep': {
        'name': 'Profundo (4 capas)',
        'layers': [256, 128, 64, 32],
        'dropout': 0.3,
        'description': 'Modelo profundo con 4 capas densas'
    },
    'wide': {
        'name': 'Ancho (2 capas grandes)',
        'layers': [256, 128],
        'dropout': 0.2,
        'description': 'Modelo con capas m√°s anchas para capturar patrones complejos'
    },
    'robust': {
        'name': 'Robusto (5 capas con regularizaci√≥n)',
        'layers': [256, 128, 64, 32, 16],
        'dropout': 0.35,
        'description': 'Modelo robusto con m√°s regularizaci√≥n para datos ruidosos'
    }
}


# ==================== CLASE PRINCIPAL ====================

class BayesianNowcaster:
    """Clase principal para nowcasting bayesiano de NO‚ÇÇ."""
    
    def __init__(self):
        self.df_master = None
        self.model = None
        self.scaler_X = None
        self.scaler_y = None
        self.selected_features = []
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Inicializa el estado de la sesi√≥n."""
        if 'bnn_data_loaded' not in st.session_state:
            st.session_state.bnn_data_loaded = False
        if 'bnn_model_trained' not in st.session_state:
            st.session_state.bnn_model_trained = False
        if 'bnn_config' not in st.session_state:
            st.session_state.bnn_config = {}
        if 'bnn_show_results' not in st.session_state:
            st.session_state.bnn_show_results = False
    
    @st.cache_data(ttl=3600)
    def load_data(_self) -> pd.DataFrame:
        """Carga y preprocesa los datos con cach√©."""
        try:
            # Usar el nuevo dataset con todas las caracter√≠sticas engineered
            df = pd.read_parquet('data/super_processed/7_4_no2_with_traffic_and_1meteo_and_1trafic_id.parquet')
            df['fecha'] = pd.to_datetime(df['fecha'])
            return df
        except Exception as e:
            st.error(f"Error al cargar los datos: {str(e)}")
            return pd.DataFrame()
    
    # def create_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
    #     """Crea variables temporales para capturar patrones c√≠clicos."""
    #     df = df.copy()
        
    #     # Variables temporales b√°sicas
    #     df['hour'] = df['fecha'].dt.hour
    #     df['day_of_week'] = df['fecha'].dt.dayofweek
    #     df['month'] = df['fecha'].dt.month
    #     df['day_of_year'] = df['fecha'].dt.dayofyear
    #     df['weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
        
    #     # Variables c√≠clicas temporales
    #     df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    #     df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    #     df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    #     df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
    #     df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    #     df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    #     df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)
    #     df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)
        
    #     # Estaci√≥n del a√±o
    #     df['season'] = df['month'].apply(
    #         lambda x: 0 if x in [12,1,2] else 1 if x in [3,4,5] else 2 if x in [6,7,8] else 3
    #     )
    #     df['season_sin'] = np.sin(2 * np.pi * df['season'] / 4)
    #     df['season_cos'] = np.cos(2 * np.pi * df['season'] / 4)
        
    #     return df
    
    def prepare_nowcasting_data(self, df: pd.DataFrame, selected_features: List[str]) -> Tuple[np.ndarray, np.ndarray]:
        """
        Prepara datos para nowcasting sin usar lags de NO‚ÇÇ.
        Solo usa variables meteorol√≥gicas, de tr√°fico y temporales.
        """
        # Eliminar filas con valores faltantes en las caracter√≠sticas o target
        df_clean = df.dropna(subset=selected_features + ['no2_value']).copy()
        
        if df_clean.empty:
            st.error("No hay datos v√°lidos despu√©s de eliminar valores faltantes.")
            return np.array([]), np.array([])
        
        # Preparar caracter√≠sticas (X) y target (y)
        X = df_clean[selected_features].values
        y = df_clean['no2_value'].values
        
        return X, y
    
    def create_bayesian_model(self, input_shape: int, config: str = 'simple') -> tf.keras.Model:
        """Crea modelo bayesiano para nowcasting usando Monte Carlo Dropout."""
        
        model_config = MODEL_CONFIGS[config]
        layers = model_config['layers']
        dropout_rate = model_config['dropout']
        
        # Modelo con mejor arquitectura para aprendizaje
        model = tf.keras.Sequential([
            tf.keras.layers.Input(shape=(input_shape,), name='input_layer'),
            
            # Normalizaci√≥n batch para mejor convergencia
            tf.keras.layers.BatchNormalization(name='input_bn')
        ])
        
        # Capas densas con arquitectura mejorada
        for i, units in enumerate(layers):
            # Capa densa
            model.add(tf.keras.layers.Dense(
                units=units,
                kernel_initializer='he_normal',  # Mejor inicializaci√≥n para ReLU
                name=f'dense_{i+1}'
            ))
            
            # Normalizaci√≥n batch antes de activaci√≥n
            model.add(tf.keras.layers.BatchNormalization(name=f'bn_{i+1}'))
            
            # Activaci√≥n
            model.add(tf.keras.layers.Activation('relu', name=f'relu_{i+1}'))
            
            # Dropout bayesiano (reducido para mejor aprendizaje inicial)
            if dropout_rate > 0:
                model.add(tf.keras.layers.Dropout(
                    rate=max(0.1, dropout_rate * 0.5),  # Reducir dropout inicialmente
                    name=f'dropout_{i+1}'
                ))
        
        # Capa de salida con inicializaci√≥n m√°s conservadora
        model.add(tf.keras.layers.Dense(
            units=1,
            activation='linear',
            kernel_initializer='glorot_normal',
            name='output_layer'
        ))
        
        return model
    
    def compile_model(self, model: tf.keras.Model, learning_rate: float = 0.01):  # Learning rate m√°s alto
        """Compila el modelo con funci√≥n de p√©rdida est√°ndar."""
        
        # Optimizador con mejor configuraci√≥n
        optimizer = tf.keras.optimizers.Adam(
            learning_rate=learning_rate,
            beta_1=0.9,
            beta_2=0.999,
            epsilon=1e-7
        )
        
        model.compile(
            optimizer=optimizer,
            loss='mse',
            metrics=['mae', 'mse']
        )
        
        return model
    
    def train_model(self, X_train: np.ndarray, y_train: np.ndarray,
                   X_val: np.ndarray, y_val: np.ndarray,
                   epochs: int = 150, batch_size: int = 64, 
                   learning_rate: float = 0.01, use_early_stopping: bool = True,
                   early_stopping_patience: int = 25, reduce_lr_patience: int = 12) -> tf.keras.callbacks.History:
        """Entrena el modelo bayesiano con par√°metros configurables."""
        
        # Recompilar modelo si el learning rate ha cambiado
        current_lr = float(self.model.optimizer.learning_rate.numpy())
        if abs(current_lr - learning_rate) > 1e-6:
            self.model = self.compile_model(self.model, learning_rate=learning_rate)
        
        # Callbacks configurables
        callbacks = []
        
        # Early stopping (opcional)
        if use_early_stopping:
            callbacks.append(tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=early_stopping_patience,
                restore_best_weights=True,
                verbose=1
            ))
        
        # Reduce learning rate on plateau (siempre activo)
        callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.7,
            patience=reduce_lr_patience,
            min_lr=1e-6,
            verbose=1
        ))
        
        # Learning rate scheduler (opcional, solo si no hay early stopping)
        if not use_early_stopping:
            callbacks.append(tf.keras.callbacks.LearningRateScheduler(
                lambda epoch: learning_rate * (0.95 ** epoch) if epoch < 50 else learning_rate * (0.95 ** 50) * (0.98 ** (epoch - 50)),
                verbose=0
            ))
        
        # Entrenar el modelo con verbose=1 para ver progreso
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1,
            shuffle=True
        )
        
        return history
    
    def predict_with_uncertainty(self, X: np.ndarray, n_samples: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """Realiza predicciones con cuantificaci√≥n de incertidumbre usando Monte Carlo Dropout."""
        
        if self.model is None:
            raise ValueError("El modelo no ha sido creado o entrenado")
        
        predictions = []
        
        try:
            # Convertir a tensor de TensorFlow si no lo es
            if not isinstance(X, tf.Tensor):
                X = tf.convert_to_tensor(X, dtype=tf.float32)
            
            # Muestreo Monte Carlo con dropout activo
            for i in range(n_samples):
                try:
                    # Usar un contexto limpio para cada predicci√≥n
                    with tf.name_scope(f'monte_carlo_sample_{i}'):
                        # training=True mantiene el dropout activo durante la inferencia
                        pred = self.model(X, training=True)
                        predictions.append(pred.numpy())
                except Exception as e:
                    # Si falla una predicci√≥n individual, intentar sin name_scope
                    try:
                        pred = self.model(X, training=True)
                        predictions.append(pred.numpy())
                    except Exception as e2:
                        st.warning(f"Error en muestra {i+1}/{n_samples}: {str(e2)}")
                        # Usar la √∫ltima predicci√≥n v√°lida si existe
                        if predictions:
                            predictions.append(predictions[-1])
                        else:
                            # Predicci√≥n est√°ndar como fallback
                            pred = self.model(X, training=False)
                            predictions.append(pred.numpy())
            
            if not predictions:
                raise ValueError("No se pudieron generar predicciones")
            
            predictions = np.array(predictions)
            
            # Calcular estad√≠sticas
            mean_pred = np.mean(predictions, axis=0)
            std_pred = np.std(predictions, axis=0)
            
            return mean_pred, std_pred
            
        except Exception as e:
            st.error(f"Error en predict_with_uncertainty: {str(e)}")
            st.error("Intentando predicci√≥n sin Monte Carlo como fallback...")
            
            # Fallback: predicci√≥n est√°ndar sin dropout
            try:
                pred = self.model(X, training=False)
                pred_np = pred.numpy()
                # Simular incertidumbre m√≠nima
                fake_std = np.ones_like(pred_np) * 0.1
                return pred_np, fake_std
            except Exception as e2:
                st.error(f"Error en fallback: {str(e2)}")
                raise e2
    
    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray, 
                      n_samples: int = 100) -> Dict:
        """Eval√∫a el modelo con m√©tricas de incertidumbre."""
        
        # Predicciones con incertidumbre
        y_pred_mean, y_pred_std = self.predict_with_uncertainty(X_test, n_samples)
        
        # Reshape si es necesario
        if len(y_pred_mean.shape) > 1:
            y_pred_mean = y_pred_mean.reshape(-1)
        if len(y_pred_std.shape) > 1:
            y_pred_std = y_pred_std.reshape(-1)
        if len(y_test.shape) > 1:
            y_test = y_test.reshape(-1)
        
        # M√©tricas tradicionales
        mse = mean_squared_error(y_test, y_pred_mean)
        mae = mean_absolute_error(y_test, y_pred_mean)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, y_pred_mean)
        
        # M√©tricas de incertidumbre
        mean_uncertainty = np.mean(y_pred_std)
        
        # Intervalos de confianza
        ci_lower = y_pred_mean - 1.96 * y_pred_std
        ci_upper = y_pred_mean + 1.96 * y_pred_std
        
        # Cobertura del intervalo de confianza (95%)
        within_ci = (y_test >= ci_lower) & (y_test <= ci_upper)
        coverage = np.mean(within_ci)
        
        # Debug: Informaci√≥n adicional para diagnosticar el problema
        debug_info = {
            'n_samples': len(y_test),
            'n_within_ci': np.sum(within_ci),
            'y_test_range': (np.min(y_test), np.max(y_test)),
            'pred_mean_range': (np.min(y_pred_mean), np.max(y_pred_mean)),
            'pred_std_range': (np.min(y_pred_std), np.max(y_pred_std)),
            'ci_lower_range': (np.min(ci_lower), np.max(ci_lower)),
            'ci_upper_range': (np.min(ci_upper), np.max(ci_upper)),
            'mean_ci_width': np.mean(ci_upper - ci_lower)
        }
        
        # Ancho promedio del intervalo de confianza
        interval_width = np.mean(ci_upper - ci_lower)
        
        return {
            'mse': mse,
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mean_uncertainty': mean_uncertainty,
            'coverage_95': coverage,
            'interval_width': interval_width,
            'predictions_mean': y_pred_mean,
            'predictions_std': y_pred_std,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'debug_info': debug_info
        }


# ==================== FUNCIONES DE VISUALIZACI√ìN ====================

def show_uncertainty_predictions(df_test: pd.DataFrame, metrics: Dict, n_points: int = 500):
    """Muestra las predicciones con bandas de incertidumbre y controles de filtrado."""
    
    # Crear DataFrame completo con todas las predicciones
    df_viz = df_test.copy()
    df_viz['pred_mean'] = metrics['predictions_mean']
    df_viz['pred_std'] = metrics['predictions_std']
    df_viz['ci_lower'] = metrics['ci_lower']
    df_viz['ci_upper'] = metrics['ci_upper']
    df_viz = df_viz.set_index('fecha')
    
    st.subheader(" Predicciones con Incertidumbre")
    
    # Controles para filtrado temporal
    col1, col2 = st.columns(2)
    
    with col1:
        date_range = st.date_input(
            "Rango de fechas para visualizar:",
            value=(df_viz.index.min().date(), df_viz.index.max().date()),
            min_value=df_viz.index.min().date(),
            max_value=df_viz.index.max().date(),
            key="uncertainty_predictions_date_range"
        )
    
    with col2:
        granularity = st.selectbox(
            "Granularidad:",
            options=['Horaria', 'Media Diaria', 'Media Semanal'],
            index=0,
            key="uncertainty_predictions_granularity"
        )
    
    # Filtrar por fechas
    start_date = pd.to_datetime(date_range[0])
    end_date = pd.to_datetime(date_range[1]) + timedelta(days=1)
    df_filtered = df_viz[(df_viz.index >= start_date) & (df_viz.index < end_date)]
    
    if df_filtered.empty:
        st.warning("No hay datos en el rango seleccionado.")
        return
    
    # Aplicar agregaci√≥n temporal con propagaci√≥n correcta de incertidumbre
    if granularity == 'Media Diaria':
        df_agg = aggregate_with_uncertainty(df_filtered, 'D')
        title = 'Predicciones Bayesianas vs Reales (Media Diaria)'
    elif granularity == 'Media Semanal':
        df_agg = aggregate_with_uncertainty(df_filtered, 'W-MON')
        title = 'Predicciones Bayesianas vs Reales (Media Semanal)'
    else:
        # Para datos horarios, submuestrear si hay demasiados puntos
        if len(df_filtered) > n_points:
            indices = np.linspace(0, len(df_filtered) - 1, n_points, dtype=int)
            df_agg = df_filtered.iloc[indices]
        else:
            df_agg = df_filtered
        title = 'Predicciones Bayesianas vs Reales (Horario)'
    
    # Crear gr√°fico con matplotlib
    fig, ax = plt.subplots(figsize=(15, 8))
    
    # Colores elegantes
    color_real = '#2E86AB'      # Azul elegante
    color_pred = '#A23B72'      # Magenta oscuro
    color_ci = '#F18F01'        # Naranja c√°lido
    
    # 1. Banda de incertidumbre (95% CI)
    ax.fill_between(
        df_agg.index, 
        df_agg['ci_lower'], 
        df_agg['ci_upper'],
        color=color_ci, 
        alpha=0.2, 
        label='Intervalo Confianza 95%',
        zorder=1
    )
    
    # 2. L√≠neas de los l√≠mites del IC (m√°s sutil)
    ax.plot(df_agg.index, df_agg['ci_lower'], color=color_ci, alpha=0.4, linewidth=0.8, zorder=2)
    ax.plot(df_agg.index, df_agg['ci_upper'], color=color_ci, alpha=0.4, linewidth=0.8, zorder=2)
    
    # 3. Valores reales
    ax.plot(
        df_agg.index, 
        df_agg['no2_value'], 
        label='Valor Real', 
        color=color_real,
        alpha=0.8, 
        linewidth=2.5,
        zorder=3
    )
    
    # 4. Predicci√≥n media
    ax.plot(
        df_agg.index, 
        df_agg['pred_mean'], 
        label='Predicci√≥n Bayesiana', 
        color=color_pred,
        linestyle='--', 
        alpha=0.9, 
        linewidth=2.5,
        zorder=4
    )
    
    # Formatear eje X seg√∫n granularidad
    if granularity == 'Horaria':
        if len(df_agg) > 48:  # M√°s de 2 d√≠as
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
        else:
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%d %H:%M'))
    else:
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    
    # Rotar fechas para mejor legibilidad
    fig.autofmt_xdate()
    
    # Estilo del gr√°fico
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
    ax.set_ylabel('Concentraci√≥n NO‚ÇÇ (¬µg/m¬≥)', fontsize=12)
    ax.set_xlabel('Fecha', fontsize=12)
    
    # Leyenda elegante
    legend = ax.legend(
        loc='upper left', 
        frameon=True, 
        fancybox=True, 
        shadow=True,
        fontsize=11
    )
    legend.get_frame().set_facecolor('white')
    legend.get_frame().set_alpha(0.9)
    
    # Grilla sutil
    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
    ax.set_facecolor('#FAFAFA')
    
    # Mejorar los ticks
    ax.tick_params(axis='both', which='major', labelsize=10)
    
    # Ajustar layout
    plt.tight_layout()
    
    # Mostrar el gr√°fico
    st.pyplot(fig)
    plt.close()
    
    # Panel de estad√≠sticas
    st.markdown("---")
    
    # Calcular m√©tricas
    mae = np.mean(np.abs(df_agg['no2_value'] - df_agg['pred_mean']))
    rmse = np.sqrt(np.mean((df_agg['no2_value'] - df_agg['pred_mean'])**2))
    coverage = np.mean((df_agg['no2_value'] >= df_agg['ci_lower']) & 
                      (df_agg['no2_value'] <= df_agg['ci_upper']))
    correlation = np.corrcoef(df_agg['no2_value'], df_agg['pred_mean'])[0, 1]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Puntos de Datos",
            f"{len(df_agg):,}",
            help="N√∫mero de puntos en el per√≠odo seleccionado"
        )
    
    with col2:
        st.metric(
            "RMSE",
            f"{rmse:.2f} ¬µg/m¬≥",
            help="Error cuadr√°tico medio"
        )
    
    with col3:
        st.metric(
            "Cobertura IC 95%",
            f"{coverage:.1%}",
            help="% de valores reales dentro del intervalo de confianza"
        )
    
    with col4:
        st.metric(
            "Correlaci√≥n R",
            f"{correlation:.3f}",
            help="Correlaci√≥n entre valores reales y predicciones"
        )
    
    # Mostrar estad√≠sticas de agregaci√≥n si aplica
    if granularity != 'Horaria':
        show_aggregation_stats(df_agg, granularity)
    
    # Panel adicional con m√©tricas detalladas
    with st.expander(" M√©tricas Detalladas"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Estad√≠sticas de Error:**")
            bias = np.mean(df_agg['pred_mean'] - df_agg['no2_value'])
            mape = np.mean(np.abs((df_agg['no2_value'] - df_agg['pred_mean']) / df_agg['no2_value'])) * 100
            
            st.write(f"‚Ä¢ MAE: {mae:.2f} ¬µg/m¬≥")
            st.write(f"‚Ä¢ RMSE: {rmse:.2f} ¬µg/m¬≥")
            st.write(f"‚Ä¢ Sesgo: {bias:.2f} ¬µg/m¬≥")
            st.write(f"‚Ä¢ MAPE: {mape:.1f}%")
        
        with col2:
            st.markdown("**Estad√≠sticas de Incertidumbre:**")
            avg_uncertainty = df_agg['pred_std'].mean()
            ci_width = np.mean(df_agg['ci_upper'] - df_agg['ci_lower'])
            
            st.write(f"‚Ä¢ Incertidumbre promedio: ¬±{avg_uncertainty:.2f} ¬µg/m¬≥")
            st.write(f"‚Ä¢ Ancho IC promedio: {ci_width:.2f} ¬µg/m¬≥")
            st.write(f"‚Ä¢ Cobertura IC 95%: {coverage:.1%}")
            st.write(f"‚Ä¢ Correlaci√≥n: {correlation:.3f}")


def aggregate_with_uncertainty(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    """
    Agrega datos temporalmente con propagaci√≥n matem√°ticamente correcta de incertidumbre.
    
    Para la agregaci√≥n de incertidumbres independientes:
    - Media: œÉ_media = œÉ / ‚àön (error est√°ndar de la media)
    - Varianza total: œÉ¬≤_total = Œ£œÉ·µ¢¬≤ / n¬≤ (para medias)
    """
    
    def aggregate_group(group):
        n = len(group)
        if n == 0:
            return pd.Series({
                'no2_value': np.nan,
                'pred_mean': np.nan,
                'pred_std': np.nan,
                'ci_lower': np.nan,
                'ci_upper': np.nan,
                'n_samples': 0
            })
        
        # Medias simples
        no2_mean = group['no2_value'].mean()
        pred_mean = group['pred_mean'].mean()
        
        # Propagaci√≥n de incertidumbre para la media
        # œÉ_media = ‚àö(Œ£œÉ·µ¢¬≤) / n (error est√°ndar de la media)
        pred_std_aggregated = np.sqrt(np.sum(group['pred_std']**2)) / n
        
        # Nuevos intervalos de confianza
        ci_lower = pred_mean - 1.96 * pred_std_aggregated
        ci_upper = pred_mean + 1.96 * pred_std_aggregated
        
        return pd.Series({
            'no2_value': no2_mean,
            'pred_mean': pred_mean,
            'pred_std': pred_std_aggregated,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'n_samples': n
        })
    
    return df.groupby(pd.Grouper(freq=freq)).apply(aggregate_group).dropna()


def show_aggregation_stats(df_agg: pd.DataFrame, granularity: str):
    """Muestra estad√≠sticas sobre la agregaci√≥n temporal."""
    
    with st.expander(f" Estad√≠sticas de Agregaci√≥n {granularity}"):
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Per√≠odos agregados",
                len(df_agg),
                help=f"N√∫mero de {granularity.lower()}s en el rango seleccionado"
            )
        
        with col2:
            avg_uncertainty = df_agg['pred_std'].mean()
            st.metric(
                "Incertidumbre promedio",
                f"{avg_uncertainty:.2f} ¬µg/m¬≥",
                help="Incertidumbre media despu√©s de la agregaci√≥n temporal"
            )
        
        with col3:
            coverage = np.mean(
                (df_agg['no2_value'] >= df_agg['ci_lower']) & 
                (df_agg['no2_value'] <= df_agg['ci_upper'])
            )
            st.metric(
                "Cobertura IC 95%",
                f"{coverage:.1%}",
                help="Porcentaje de valores reales dentro del intervalo de confianza"
            )
        
        with col4:
            avg_width = (df_agg['ci_upper'] - df_agg['ci_lower']).mean()
            st.metric(
                "Ancho promedio IC",
                f"{avg_width:.2f} ¬µg/m¬≥",
                help="Ancho promedio del intervalo de confianza"
            )
        
        # Informaci√≥n matem√°tica sobre la agregaci√≥n
        st.markdown("---")
        st.markdown("""
        **üî¨ Propagaci√≥n de Incertidumbre:**
        
        - **Media temporal**: Simple promedio aritm√©tico
        - **Incertidumbre agregada**: œÉ_agregada = ‚àö(Œ£œÉ·µ¢¬≤) / n 
        - **Interpretaci√≥n**: La incertidumbre se reduce con m√°s muestras (ley de grandes n√∫meros)
        - **IC 95%**: media ¬± 1.96 √ó œÉ_agregada
        
        Este enfoque es matem√°ticamente correcto para incertidumbres independientes.
        """)


def show_uncertainty_histogram(metrics: Dict):
    """Muestra histograma de incertidumbre."""
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig_hist = go.Figure(data=[
            go.Histogram(
                x=metrics['predictions_std'],
                nbinsx=30,
                name='Incertidumbre',
                marker_color='skyblue',
                opacity=0.7
            )
        ])
        
        fig_hist.update_layout(
            title='Distribuci√≥n de la Incertidumbre',
            xaxis_title='Desviaci√≥n Est√°ndar (¬µg/m¬≥)',
            yaxis_title='Frecuencia',
            height=400
        )
        
        st.plotly_chart(fig_hist, use_container_width=True)
    
    with col2:
        # Gr√°fico de dispersi√≥n: Error vs Incertidumbre
        df_scatter = pd.DataFrame({
            'uncertainty': metrics['predictions_std'],
            'error': np.abs(metrics['predictions_mean'] - metrics.get('y_true', metrics['predictions_mean']))
        })
        
        fig_scatter = px.scatter(
            df_scatter,
            x='uncertainty',
            y='error',
            title='Error vs Incertidumbre',
            labels={
                'uncertainty': 'Incertidumbre (¬µg/m¬≥)',
                'error': 'Error Absoluto (¬µg/m¬≥)'
            },
            opacity=0.6,
            height=400
        )
        
        st.plotly_chart(fig_scatter, use_container_width=True)


def show_model_metrics(metrics: Dict):
    """Muestra m√©tricas del modelo en formato dashboard."""
        
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="RMSE",
            value=f"{metrics['rmse']:.2f}",
            help="Error cuadr√°tico medio"
        )
        
    with col2:
        st.metric(
            label="MAE",
            value=f"{metrics['mae']:.2f}",
            help="Error absoluto medio"
        )
        
    with col3:
        st.metric(
            label="R¬≤",
            value=f"{metrics['r2']:.3f}",
            help="Coeficiente de determinaci√≥n"
        )
        
    with col4:
        st.metric(
            label="Incertidumbre Media",
            value=f"{metrics['mean_uncertainty']:.2f}",
            help="Incertidumbre promedio de las predicciones"
        )
    
    # Segunda fila de m√©tricas espec√≠ficas de incertidumbre
    col5, col6 = st.columns(2)
    
    with col5:
        coverage_color = "normal" if 0.90 <= metrics['coverage_95'] <= 0.98 else "inverse"
        st.metric(
            label="Cobertura IC 95%",
            value=f"{metrics['coverage_95']:.1%}",
            help="Porcentaje de valores reales dentro del intervalo de confianza del 95%",
            delta=f"{metrics['coverage_95'] - 0.95:.1%}" if coverage_color == "normal" else None
        )
        
    with col6:
        st.metric(
            label="Ancho IC Promedio",
            value=f"{metrics['interval_width']:.2f}",
            help="Ancho promedio del intervalo de confianza del 95%"
        )


def show_training_history(history):
    """Muestra la historia del entrenamiento con an√°lisis detallado."""
    
    if history is None:
        st.warning("No hay historia de entrenamiento disponible")
        return
    
    # Crear gr√°ficos de entrenamiento
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    epochs = range(1, len(history.history['loss']) + 1)
    
    # Gr√°fico 1: P√©rdida
    ax1.plot(epochs, history.history['loss'], 'b-', label='Entrenamiento', linewidth=2)
    ax1.plot(epochs, history.history['val_loss'], 'r-', label='Validaci√≥n', linewidth=2)
    ax1.set_title('P√©rdida durante el Entrenamiento', fontsize=14, fontweight='bold')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('MSE Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # An√°lisis de convergencia
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]
    min_val_loss = min(history.history['val_loss'])
    min_val_epoch = history.history['val_loss'].index(min_val_loss) + 1
    
    ax1.axhline(y=min_val_loss, color='orange', linestyle='--', alpha=0.7, 
                label=f'Mejor val_loss: {min_val_loss:.4f} (√©poca {min_val_epoch})')
    ax1.legend()
    
    # Gr√°fico 2: MAE
    ax2.plot(epochs, history.history['mae'], 'b-', label='Entrenamiento MAE', linewidth=2)
    ax2.plot(epochs, history.history['val_mae'], 'r-', label='Validaci√≥n MAE', linewidth=2)
    ax2.set_title('Error Absoluto Medio (MAE)', fontsize=14, fontweight='bold')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('MAE')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Gr√°fico 3: Ratio Val/Train Loss
    ratio_loss = [val/train for val, train in zip(history.history['val_loss'], history.history['loss'])]
    ax3.plot(epochs, ratio_loss, 'g-', linewidth=2)
    ax3.set_title('Ratio Validaci√≥n/Entrenamiento Loss', fontsize=14, fontweight='bold')
    ax3.set_xlabel('√âpoca')
    ax3.set_ylabel('Val Loss / Train Loss')
    ax3.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Ratio = 1.0')
    ax3.axhline(y=1.2, color='orange', linestyle='--', alpha=0.7, label='Ratio = 1.2 (l√≠mite saludable)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Gr√°fico 4: Smoothed Loss (media m√≥vil)
    window = max(1, len(epochs) // 10)  # Ventana del 10% de las √©pocas
    if len(epochs) > window:
        train_smooth = pd.Series(history.history['loss']).rolling(window=window, center=True).mean()
        val_smooth = pd.Series(history.history['val_loss']).rolling(window=window, center=True).mean()
        
        ax4.plot(epochs, train_smooth, 'b-', label='Entrenamiento (suavizado)', linewidth=2)
        ax4.plot(epochs, val_smooth, 'r-', label='Validaci√≥n (suavizado)', linewidth=2)
        ax4.set_title(f'P√©rdida Suavizada (ventana={window})', fontsize=14, fontweight='bold')
        ax4.set_xlabel('√âpoca')
        ax4.set_ylabel('MSE Loss (suavizado)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
    else:
        ax4.text(0.5, 0.5, 'Pocas √©pocas para\nsuavizado', 
                ha='center', va='center', transform=ax4.transAxes, fontsize=12)
        ax4.set_title('P√©rdida Suavizada', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # An√°lisis de diagn√≥stico
    st.subheader("üîç An√°lisis de Diagn√≥stico del Entrenamiento")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("√âpocas Entrenadas", len(epochs))
        st.metric("P√©rdida Final (Train)", f"{final_train_loss:.4f}")
        st.metric("P√©rdida Final (Val)", f"{final_val_loss:.4f}")
    
    with col2:
        st.metric("Mejor Val Loss", f"{min_val_loss:.4f}")
        st.metric("√âpoca del Mejor Modelo", min_val_epoch)
        overfitting_ratio = final_val_loss / final_train_loss
        st.metric("Ratio Final Val/Train", f"{overfitting_ratio:.2f}")
    
    with col3:
        # An√°lisis de tendencias
        recent_epochs = min(10, len(epochs) // 4)  # √öltimas 25% de √©pocas o 10, lo que sea menor
        if recent_epochs > 1:
            recent_train_trend = np.polyfit(range(recent_epochs), 
                                          history.history['loss'][-recent_epochs:], 1)[0]
            recent_val_trend = np.polyfit(range(recent_epochs), 
                                        history.history['val_loss'][-recent_epochs:], 1)[0]
            
            st.metric("Tendencia Train (√∫ltimas √©pocas)", 
                     f"{'‚Üì' if recent_train_trend < 0 else '‚Üë'} {abs(recent_train_trend):.6f}")
            st.metric("Tendencia Val (√∫ltimas √©pocas)", 
                     f"{'‚Üì' if recent_val_trend < 0 else '‚Üë'} {abs(recent_val_trend):.6f}")
        
        # Estabilidad del entrenamiento
        train_stability = np.std(history.history['loss'][-recent_epochs:]) if recent_epochs > 1 else 0
        st.metric("Estabilidad Train", f"{train_stability:.4f}")
    
    # Diagn√≥stico de problemas
    st.subheader("‚ö†Ô∏è Diagn√≥stico de Problemas")
    
    diagnostics = []
    
    # 1. Overfitting
    if overfitting_ratio > 1.5:
        diagnostics.append("üî¥ **Overfitting severo**: Ratio val/train > 1.5. Considera reducir complejidad del modelo o aumentar regularizaci√≥n.")
    elif overfitting_ratio > 1.2:
        diagnostics.append("üü° **Overfitting moderado**: Ratio val/train > 1.2. Monitorear de cerca.")
    else:
        diagnostics.append("üü¢ **Sin overfitting significativo**: Ratio val/train saludable.")
    
    # 2. Convergencia
    if len(epochs) >= 100:  # Solo si entren√≥ suficientes √©pocas
        if recent_train_trend > -1e-5:  # P√©rdida de entrenamiento no est√° bajando
            diagnostics.append("üî¥ **Problema de convergencia**: La p√©rdida de entrenamiento no est√° disminuyendo.")
        
        if recent_val_trend > 1e-5:  # P√©rdida de validaci√≥n est√° subiendo
            diagnostics.append("üü° **P√©rdida de validaci√≥n creciente**: Posible overfitting o fin de mejora.")
    
    # 3. Estabilidad
    if train_stability > final_train_loss * 0.1:  # Variabilidad > 10% de la p√©rdida final
        diagnostics.append("üü° **Entrenamiento inestable**: Alta variabilidad en las √∫ltimas √©pocas.")
    
    # 4. Early stopping
    epochs_since_best = len(epochs) - min_val_epoch
    if epochs_since_best > 20:
        diagnostics.append(f"üü° **Early stopping**: {epochs_since_best} √©pocas desde el mejor modelo. Considera reducir paciencia.")
    
    # 5. Learning rate
    if final_val_loss > min_val_loss * 1.1:  # P√©rdida final > 10% del m√≠nimo
        diagnostics.append("üü° **Posible learning rate alto**: La p√©rdida final es significativamente mayor que el m√≠nimo alcanzado.")
    
    # Mostrar diagn√≥sticos
    for diagnostic in diagnostics:
        st.markdown(diagnostic)
    
    if not diagnostics:
        st.success("üü¢ **Entrenamiento exitoso**: No se detectaron problemas significativos.")
    
    # Recomendaciones
    st.subheader("üí° Recomendaciones")
    
    recommendations = []
    
    if overfitting_ratio > 1.3:
        recommendations.append("- Aumentar dropout rate o a√±adir m√°s regularizaci√≥n")
        recommendations.append("- Reducir complejidad del modelo (menos capas/neuronas)")
        recommendations.append("- Aumentar el tama√±o del conjunto de entrenamiento")
    
    if recent_train_trend > -1e-5 and len(epochs) >= 50:
        recommendations.append("- Aumentar learning rate si est√° muy bajo")
        recommendations.append("- Verificar que los datos est√©n correctamente normalizados")
        recommendations.append("- Considerar una arquitectura diferente")
    
    if train_stability > final_train_loss * 0.1:
        recommendations.append("- Reducir learning rate para mayor estabilidad")
        recommendations.append("- Aumentar batch size")
        recommendations.append("- A√±adir batch normalization")
    
    if not recommendations:
        recommendations.append("- El entrenamiento parece estar funcionando correctamente")
        recommendations.append("- Continuar monitoreando el rendimiento en datos de prueba")
    
    for rec in recommendations:
        st.markdown(rec)


# ==================== FUNCI√ìN PRINCIPAL ====================

def bayesian_nowcasting_page():
    """Funci√≥n principal para la p√°gina de nowcasting bayesiano."""
    
    # Inicializar el nowcaster
    nowcaster = BayesianNowcaster()
    
    # Panel de informaci√≥n
    show_info_panel()
    
    # Cargar datos
    if not st.session_state.bnn_data_loaded:
        if st.button("üîÑ Cargar datos para Nowcasting Bayesiano", type="primary"):
            with st.spinner("Cargando datos..."):
                nowcaster.df_master = nowcaster.load_data()
                if not nowcaster.df_master.empty:
                    # Crear caracter√≠sticas temporales y de retraso
                    st.session_state.bnn_data_loaded = True
                    st.success("‚úÖ Datos cargados correctamente")
                    st.rerun()
        return
    
    # Recuperar datos
    nowcaster.df_master = nowcaster.load_data()
    
    if nowcaster.df_master.empty:
        st.error("No se pudieron cargar los datos.")
        return
    
    # Configuraci√≥n del nowcasting
    st.subheader(" Configuraci√≥n del Nowcasting")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Selecci√≥n de sensor
        sensores = sorted(nowcaster.df_master['id_no2'].unique())
        sensor_seleccionado = st.selectbox(
            "Sensor de NO‚ÇÇ", 
            sensores, 
            index=2 if len(sensores) > 2 else 0,
            key="sensor_selection"
        )
        
        # Filtrar por sensor
        df_sensor = nowcaster.df_master[nowcaster.df_master['id_no2'] == sensor_seleccionado]
        
        # Fechas disponibles
        fecha_min = df_sensor["fecha"].min().date()
        fecha_max = df_sensor["fecha"].max().date()
        
        # Fecha de divisi√≥n
        fecha_division = st.date_input(
            "Fecha de divisi√≥n (entrenamiento/evaluaci√≥n)",
            value=pd.to_datetime('2024-01-01').date(),
            min_value=fecha_min,
            max_value=fecha_max,
            help="Los datos anteriores se usan para entrenamiento, posteriores para evaluaci√≥n",
            key="split_date"
        )
    
    with col2:
        # Configuraci√≥n del modelo
        model_type = st.selectbox(
            "Arquitectura del modelo",
            options=list(MODEL_CONFIGS.keys()),
            format_func=lambda x: MODEL_CONFIGS[x]['name'],
            help="Selecciona la complejidad del modelo bayesiano",
            key="model_architecture"
        )
        
        # Mostrar descripci√≥n del modelo
        st.info(f"üìã **{MODEL_CONFIGS[model_type]['name']}**: {MODEL_CONFIGS[model_type]['description']}")
    
    # Selecci√≥n de variables
    st.subheader("üîß Selecci√≥n de Variables")
    
    # Crear tabs para categor√≠as usando VARIABLE_CATEGORIES
    var_tabs = st.tabs(list(VARIABLE_CATEGORIES.keys()))
    
    selected_features = []
    for i, (category, vars_list) in enumerate(VARIABLE_CATEGORIES.items()):
        with var_tabs[i]:
            # Filtrar variables que existen en los datos
            available_vars = [var for var in vars_list if var in nowcaster.df_master.columns or 'sin' in var or 'cos' in var]
            
            # Configurar defaults - todas las variables disponibles
            default_vars = available_vars
            
            selected_in_category = st.multiselect(
                f"Variables de {category}",
                available_vars,
                default=default_vars,
                help=f"Selecciona las variables de {category.lower()} para el modelo",
                key=f"vars_{category.replace(' ', '_').lower()}"
            )
            selected_features.extend(selected_in_category)
    
    if not selected_features:
        st.warning("Selecciona al menos una variable para continuar.")
        return
    
    nowcaster.selected_features = selected_features
    
    # ==================== CONFIGURACI√ìN DE ENTRENAMIENTO ====================
    st.subheader("‚öôÔ∏è Configuraci√≥n de Entrenamiento")
    
    # Crear dos columnas para los controles
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("** Par√°metros Principales**")
        
        # Learning Rate
        learning_rate = st.number_input(
            "Learning Rate",
            min_value=0.0001,
            max_value=0.1,
            value=0.01,
            step=0.001,
            format="%.4f",
            help="Tasa de aprendizaje del optimizador. Valores m√°s altos = convergencia m√°s r√°pida pero menos estable"
        )
        
        # √âpocas
        epochs = st.number_input(
            "N√∫mero m√°ximo de √©pocas",
            min_value=10,
            max_value=500,
            value=150,
            step=10,
            help="N√∫mero m√°ximo de √©pocas de entrenamiento"
        )
        
        # Batch Size
        batch_size = st.selectbox(
            "Batch Size",
            options=[16, 32, 64, 128, 256],
            index=2,  # 64 por defecto
            help="Tama√±o del lote para entrenamiento. Valores m√°s grandes = entrenamiento m√°s estable"
        )
    
    with col2:
        st.markdown("**üõë Control de Parada**")
        
        # Early Stopping
        use_early_stopping = st.checkbox(
            "Activar Early Stopping",
            value=True,
            help="Detener entrenamiento autom√°ticamente cuando no mejore la validaci√≥n"
        )
        
        # Paciencia Early Stopping
        if use_early_stopping:
            early_stopping_patience = st.number_input(
                "Paciencia Early Stopping",
                min_value=5,
                max_value=50,
                value=25,
                step=5,
                help="N√∫mero de √©pocas sin mejora antes de detener el entrenamiento"
            )
        else:
            early_stopping_patience = 25
        
        # Paciencia Reduce LR
        reduce_lr_patience = st.number_input(
            "Paciencia Reduce LR",
            min_value=3,
            max_value=30,
            value=12,
            step=2,
            help="√âpocas sin mejora antes de reducir learning rate"
        )
    
    # Crear configuraci√≥n de entrenamiento
    training_config = {
        'learning_rate': learning_rate,
        'batch_size': batch_size,
        'epochs': epochs,
        'use_early_stopping': use_early_stopping,
        'early_stopping_patience': early_stopping_patience,
        'reduce_lr_patience': reduce_lr_patience
    }
    
    # # Mostrar resumen de configuraci√≥n de entrenamiento
    # with st.expander("üìã Resumen de Configuraci√≥n de Entrenamiento"):
    #     col1, col2, col3 = st.columns(3)
        
    #     with col1:
    #         st.write("**Optimizaci√≥n:**")
    #         st.write(f"- Learning Rate: {learning_rate}")
    #         st.write(f"- Batch Size: {batch_size}")
    #         st.write(f"- √âpocas m√°x: {epochs}")
        
    #     with col2:
    #         st.write("**Control de Parada:**")
    #         st.write(f"- Early Stopping: {'‚úÖ' if use_early_stopping else '‚ùå'}")
    #         if use_early_stopping:
    #             st.write(f"- Paciencia ES: {early_stopping_patience}")
    #         st.write(f"- Paciencia LR: {reduce_lr_patience}")
        
    #     with col3:
    #         st.write("**Estimaci√≥n:**")
    #         if use_early_stopping:
    #             est_time = "5-30 min"
    #             est_epochs = f"20-{min(epochs, early_stopping_patience + 20)}"
    #         else:
    #             est_time = f"{epochs * 0.1:.0f}-{epochs * 0.3:.0f} min"
    #             est_epochs = str(epochs)
    #         st.write(f"- Tiempo estimado: {est_time}")
    #         st.write(f"- √âpocas esperadas: {est_epochs}")
    
    # Mostrar resumen de configuraci√≥n
    with st.expander("üìã Resumen de Configuraci√≥n"):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.write(f"**Sensor:** {sensor_seleccionado}")
            st.write(f"**Variables:** {len(selected_features)}")
        with col2:
            st.write(f"**Arquitectura:** {MODEL_CONFIGS[model_type]['name']}")
        with col3:
            st.write(f"**Fecha divisi√≥n:** {fecha_division}")
    
    # Preparar datos
    with st.spinner("Preparando datos para entrenamiento..."):
        df_processed = df_sensor.copy()
        
        # Limpiar datos
        df_clean = df_processed.dropna(subset=selected_features + ['no2_value'])
        
        if len(df_clean) < 1000:
            st.error("‚ùå Datos insuficientes despu√©s de limpiar NaN")
            return
        
        # Dividir datos temporalmente
        fecha_division_dt = pd.to_datetime(fecha_division)
        train_data = df_clean[df_clean['fecha'] <= fecha_division_dt]
        test_data = df_clean[df_clean['fecha'] > fecha_division_dt]
        
        if len(train_data) < 500 or len(test_data) < 100:
            st.error("‚ùå No hay suficientes datos para entrenamiento o evaluaci√≥n.")
            return
    
    # Mostrar informaci√≥n de datos
    st.subheader(" Informaci√≥n del Conjunto de Datos")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Registros totales", len(df_clean))
    with col2:
        st.metric("Entrenamiento", len(train_data))
    with col3:
        st.metric("Evaluaci√≥n", len(test_data))
    with col4:
        st.metric("Variables", len(selected_features))
    
    # Verificar si existe modelo entrenado
    config_key = f"{sensor_seleccionado}_{model_type}_{len(selected_features)}"
    
    # Botones de acci√≥n
    col1, col2 = st.columns(2)
    
    with col1:
        if st.session_state.bnn_model_trained and st.session_state.get('bnn_config_key') == config_key:
            analyze_button = st.button("Ver Resultados del Modelo", type="primary")
        else:
            analyze_button = False
            if st.session_state.bnn_model_trained:
                st.info("Configuraci√≥n cambiada - Entrena un nuevo modelo")
            else:
                st.info("No existe un modelo entrenado con esta configuraci√≥n")
    
    with col2:
        train_button = st.button("Entrenar Modelo Bayesiano", type="secondary")
    
    # Procesar acciones
    if train_button:
        if len(selected_features) == 0:
            st.error("‚ùå Selecciona al menos un grupo de variables")
        else:
            st.session_state.bnn_config_key = config_key
            st.session_state.bnn_show_results = False  # Reset visualizaci√≥n
            train_bayesian_model(
                nowcaster, train_data, test_data, model_type, sensor_seleccionado,
                training_config
            )
    
    elif analyze_button and st.session_state.bnn_model_trained:
        st.session_state.bnn_show_results = True
    
    # Mostrar resultados si est√° activo el flag
    if st.session_state.get('bnn_show_results', False) and st.session_state.bnn_model_trained:
        show_model_results()
    
    # Si no se ha entrenado un modelo, mostrar resumen de datos
    elif not st.session_state.bnn_model_trained:
        show_data_summary(df_clean)


def show_info_panel():
    """Muestra panel de informaci√≥n sobre el nowcasting bayesiano."""
    
    # st.markdown("""
    # ### üß† Nowcasting Bayesiano de NO‚ÇÇ
    
    # Implementaci√≥n de **redes neuronales bayesianas** para nowcasting de NO‚ÇÇ con 
    # **cuantificaci√≥n de incertidumbre** mediante muestreo Monte Carlo.
    # """)
    
    # Mostrar informaci√≥n sobre el m√©todo
    with st.expander("‚ÑπÔ∏è Acerca del Nowcasting Bayesiano", expanded=False):
        st.markdown("""
        **Nowcasting Bayesiano de NO‚ÇÇ**
        
        Implementaci√≥n de **redes neuronales bayesianas** para predicci√≥n inmediata de NO‚ÇÇ 
        basada √∫nicamente en **variables meteorol√≥gicas y de tr√°fico actuales**.
        
        **Ventajas clave:**
        - ** Aplicable a cualquier ciudad**: No requiere datos hist√≥ricos de NO‚ÇÇ
        - ** Predicci√≥n en tiempo real**: Basado en condiciones actuales
        - ** Cuantificaci√≥n de incertidumbre**: Intervalos de confianza mediante Monte Carlo
        - ** Modelado bayesiano**: Captura incertidumbre epist√©mica y aleatoria
        
        **Metodolog√≠a:**
        1. **Entrada**: Variables meteorol√≥gicas + tr√°fico + temporales
        2. **Procesamiento**: Red neuronal bayesiana con capas variacionales
        3. **Salida**: Media de predicci√≥n + intervalo de incertidumbre
        4. **Muestreo**: Monte Carlo para estimar distribuci√≥n posterior
        
        **Variables disponibles:**
        - **Meteorol√≥gicas**: Temperatura, humedad, viento, presi√≥n, radiaci√≥n solar
        - **Tr√°fico**: Intensidad, velocidad, ocupaci√≥n, carga vial  
        - **Temporales**: Hora, d√≠a, mes, patrones c√≠clicos estacionales
        
        **‚ö†Ô∏è Nota importante:**
        Este modelo **NO utiliza valores hist√≥ricos de NO‚ÇÇ**, lo que permite su 
        aplicaci√≥n directa a ciudades sin sensores de calidad del aire existentes.
        """)
        
        st.markdown("---")
        st.markdown("""
        ** Casos de uso ideales:**
        - Implementaci√≥n en ciudades sin red de monitoreo
        - Validaci√≥n de sensores existentes
        - Predicci√≥n en tiempo real para alertas
        - Estudios de impacto ambiental
        """)


def train_bayesian_model(nowcaster, train_data, test_data, model_type, sensor_id, 
                        training_config):
    """Entrena el modelo bayesiano con configuraci√≥n personalizable."""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üîÑ Preparando datos...")
        progress_bar.progress(20)
        
        # Preparar datos (ahora son arrays 2D: [samples, features])
        X_train, y_train = nowcaster.prepare_nowcasting_data(train_data, nowcaster.selected_features)
        X_test, y_test = nowcaster.prepare_nowcasting_data(test_data, nowcaster.selected_features)
        
        if len(X_train) == 0 or len(X_test) == 0:
            st.error("‚ùå No se pudieron preparar suficientes datos")
            return
        
        st.write(f"**Datos preparados:**")
        st.write(f"- Entrenamiento: {X_train.shape}")
        st.write(f"- Evaluaci√≥n: {X_test.shape}")
        st.write(f"- Caracter√≠sticas: {len(nowcaster.selected_features)}")
        
        # Divisi√≥n de validaci√≥n temporal (80% train, 20% val)
        val_split = int(0.8 * len(X_train))
        X_val = X_train[val_split:]
        y_val = y_train[val_split:]
        X_train = X_train[:val_split]
        y_train = y_train[:val_split]
        
        st.write(f"**Divisi√≥n de datos:**")
        st.write(f"- Entrenamiento final: {X_train.shape[0]} muestras")
        st.write(f"- Validaci√≥n: {X_val.shape[0]} muestras")
        st.write(f"- Prueba: {X_test.shape[0]} muestras")
        
        status_text.text("üîÑ Normalizando datos...")
        progress_bar.progress(30)
        
        # Normalizar datos con verificaci√≥n
        nowcaster.scaler_X = StandardScaler()
        X_train_scaled = nowcaster.scaler_X.fit_transform(X_train)
        X_val_scaled = nowcaster.scaler_X.transform(X_val)
        X_test_scaled = nowcaster.scaler_X.transform(X_test)
        
        nowcaster.scaler_y = StandardScaler()
        y_train_scaled = nowcaster.scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
        y_val_scaled = nowcaster.scaler_y.transform(y_val.reshape(-1, 1)).flatten()
        
        # Verificar normalizaci√≥n
        st.write(f"**Verificaci√≥n de normalizaci√≥n:**")
        st.write(f"- X_train_scaled media: {X_train_scaled.mean():.3f} ¬± {X_train_scaled.std():.3f}")
        st.write(f"- y_train_scaled media: {y_train_scaled.mean():.3f} ¬± {y_train_scaled.std():.3f}")
        st.write(f"- X_train_scaled rango: [{X_train_scaled.min():.3f}, {X_train_scaled.max():.3f}]")
        st.write(f"- y_train_scaled rango: [{y_train_scaled.min():.3f}, {y_train_scaled.max():.3f}]")
        
        status_text.text("üîÑ Creando modelo...")
        progress_bar.progress(40)
        
        # Crear y compilar modelo
        nowcaster.model = nowcaster.create_bayesian_model(X_train_scaled.shape[1], model_type)
        nowcaster.model = nowcaster.compile_model(nowcaster.model, learning_rate=training_config['learning_rate'])
        
        st.write(f"**Modelo creado:**")
        st.write(f"- Input shape: {X_train_scaled.shape[1]}")
        st.write(f"- Arquitectura: {MODEL_CONFIGS[model_type]['name']}")
        st.write(f"- Par√°metros totales: {nowcaster.model.count_params():,}")
        
        # Mostrar resumen del modelo
        with st.expander("üîç Ver arquitectura del modelo"):
            model_summary = []
            nowcaster.model.summary(print_fn=lambda x: model_summary.append(x))
            st.text('\n'.join(model_summary))
        
        status_text.text("Entrenando modelo...")
        progress_bar.progress(50)
        
        # Crear contenedor para mostrar progreso de entrenamiento
        training_container = st.empty()
        
        # Mostrar configuraci√≥n de entrenamiento
        with training_container.container():
            st.write("**Configuraci√≥n de entrenamiento:**")
            st.write(f"- Learning rate: {training_config['learning_rate']}")
            st.write(f"- Batch size: {training_config['batch_size']}")
            st.write(f"- √âpocas m√°ximas: {training_config['epochs']}")
            st.write(f"- Early stopping: {'‚úÖ Activado' if training_config['use_early_stopping'] else '‚ùå Desactivado'}")
            if training_config['use_early_stopping']:
                st.write(f"- Paciencia early stopping: {training_config['early_stopping_patience']} √©pocas")
            st.write(f"- Paciencia reduce LR: {training_config['reduce_lr_patience']} √©pocas")
        
        # Entrenar modelo con configuraci√≥n personalizada
        history = nowcaster.train_model(
            X_train_scaled, y_train_scaled,
            X_val_scaled, y_val_scaled,
            epochs=training_config['epochs'],
            batch_size=training_config['batch_size'],
            learning_rate=training_config['learning_rate'],
            use_early_stopping=training_config['use_early_stopping'],
            early_stopping_patience=training_config['early_stopping_patience'],
            reduce_lr_patience=training_config['reduce_lr_patience']
        )
        
        # Mostrar informaci√≥n del entrenamiento completado
        with training_container.container():
            st.write("‚úÖ **Entrenamiento completado!**")
            final_epoch = len(history.history['loss'])
            final_train_loss = history.history['loss'][-1]
            final_val_loss = history.history['val_loss'][-1]
            st.write(f"- √âpocas entrenadas: {final_epoch}")
            st.write(f"- P√©rdida final entrenamiento: {final_train_loss:.4f}")
            st.write(f"- P√©rdida final validaci√≥n: {final_val_loss:.4f}")
            st.write(f"- Ratio val/train loss: {final_val_loss/final_train_loss:.2f}")
            
            # Informaci√≥n adicional sobre early stopping
            if training_config['use_early_stopping'] and final_epoch < training_config['epochs']:
                st.write(f"- ‚èπÔ∏è Early stopping activado en √©poca {final_epoch}")
            elif final_epoch == training_config['epochs']:
                st.write(f"- üèÅ Entrenamiento completado (m√°ximo de √©pocas alcanzado)")
        
        status_text.text(" Evaluando modelo...")
        progress_bar.progress(90)
        
        # Evaluar modelo - IMPORTANTE: usar datos desnormalizados para m√©tricas finales
        y_pred_mean_scaled, y_pred_std_scaled = nowcaster.predict_with_uncertainty(
            X_test_scaled, n_samples=100
        )
        
        # Desnormalizar predicciones
        y_pred_mean = nowcaster.scaler_y.inverse_transform(
            y_pred_mean_scaled.reshape(-1, 1)
        ).flatten()
        
        # Para la desviaci√≥n est√°ndar, escalar por la std del scaler
        y_pred_std = y_pred_std_scaled.flatten() * nowcaster.scaler_y.scale_[0]
        
        # Verificar desnormalizaci√≥n
        st.write(f"üìà **Verificaci√≥n de predicciones:**")
        st.write(f"- Predicciones rango: [{y_pred_mean.min():.2f}, {y_pred_mean.max():.2f}] ¬µg/m¬≥")
        st.write(f"- Incertidumbre media: {y_pred_std.mean():.2f} ¬µg/m¬≥")
        st.write(f"- Valores reales rango: [{y_test.min():.2f}, {y_test.max():.2f}] ¬µg/m¬≥")
        
        # Calcular intervalos de confianza desnormalizados
        ci_lower = y_pred_mean - 1.96 * y_pred_std
        ci_upper = y_pred_mean + 1.96 * y_pred_std
        
        # Calcular cobertura con datos desnormalizados
        within_ci = (y_test >= ci_lower) & (y_test <= ci_upper)
        coverage_95 = np.mean(within_ci)
        
        # M√©tricas de incertidumbre
        mean_uncertainty = np.mean(y_pred_std)
        interval_width = np.mean(ci_upper - ci_lower)
        
        # Debug info
        debug_info = {
            'n_samples': len(y_test),
            'n_within_ci': np.sum(within_ci),
            'y_test_range': (np.min(y_test), np.max(y_test)),
            'pred_mean_range': (np.min(y_pred_mean), np.max(y_pred_mean)),
            'pred_std_range': (np.min(y_pred_std), np.max(y_pred_std)),
            'ci_lower_range': (np.min(ci_lower), np.max(ci_lower)),
            'ci_upper_range': (np.min(ci_upper), np.max(ci_upper)),
            'mean_ci_width': interval_width,
            'training_epochs': final_epoch,
            'final_train_loss': final_train_loss,
            'final_val_loss': final_val_loss,
            'training_config': training_config
        }
        
        # Calcular todas las m√©tricas con datos desnormalizados
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        metrics = {
            'mse': mean_squared_error(y_test, y_pred_mean),
            'mae': mean_absolute_error(y_test, y_pred_mean),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_mean)),
            'r2': r2_score(y_test, y_pred_mean),
            'mean_uncertainty': mean_uncertainty,
            'coverage_95': coverage_95,
            'interval_width': interval_width,
            'predictions_mean': y_pred_mean,
            'predictions_std': y_pred_std,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'y_true': y_test,
            'debug_info': debug_info
        }
        
        # Mostrar m√©tricas preliminares
        st.write(f" **M√©tricas preliminares:**")
        st.write(f"- RMSE: {metrics['rmse']:.2f} ¬µg/m¬≥")
        st.write(f"- R¬≤: {metrics['r2']:.3f}")
        st.write(f"- Cobertura IC 95%: {coverage_95:.1%}")
        st.write(f"- Ancho promedio IC: {interval_width:.2f} ¬µg/m¬≥")
        
        # Guardar resultados en session state
        st.session_state.bnn_model_trained = True
        st.session_state.bnn_metrics = metrics
        st.session_state.bnn_history = history
        st.session_state.bnn_test_data = test_data.iloc[-len(y_test):].copy()
        st.session_state.bnn_config = {
            'model_type': model_type,
            'features': nowcaster.selected_features,
            'sensor_id': sensor_id,
            'training_config': training_config
        }
        st.session_state.bnn_show_results = True  # Activar visualizaci√≥n autom√°tica
        
        progress_bar.progress(100)
        status_text.text("‚úÖ Modelo entrenado correctamente!")
        
        st.success("üéâ ¬°Modelo bayesiano entrenado exitosamente!")
        
        # Mostrar resultados autom√°ticamente
        time.sleep(1)
        st.rerun()
        
    except Exception as e:
        import traceback
        st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
        st.error(f"üìã Detalles del error: {traceback.format_exc()}")
        progress_bar.empty()
        status_text.empty()


def show_model_results():
    """Muestra los resultados del modelo entrenado."""
    
    if 'bnn_metrics' not in st.session_state:
        st.error("‚ùå No hay resultados de modelo disponibles")
        return
    
    metrics = st.session_state.bnn_metrics
    history = st.session_state.bnn_history
    test_data = st.session_state.bnn_test_data
    config = st.session_state.bnn_config
    
    # Bot√≥n para cerrar resultados
    col1, col2, col3 = st.columns([1, 1, 8])
    # with col1:
    #     if st.button("‚ùå Cerrar", help="Cerrar visualizaci√≥n de resultados"):
    #         st.session_state.bnn_show_results = False
    #         st.rerun()
    
    st.header(" Resultados del Modelo Bayesiano")
    
    # Mostrar configuraci√≥n del modelo
    st.subheader("‚öôÔ∏è Configuraci√≥n del Modelo")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info(f"**Sensor:** {config['sensor_id']}")
        st.info(f"**Arquitectura:** {MODEL_CONFIGS[config['model_type']]['name']}")
    with col2:
        st.info(f"**Caracter√≠sticas:** {len(config['features'])}")
        # Mostrar configuraci√≥n de entrenamiento si est√° disponible
        if 'training_config' in config:
            tc = config['training_config']
            st.info(f"**Learning Rate:** {tc['learning_rate']}")
    with col3:
        if 'training_config' in config:
            tc = config['training_config']
            st.info(f"**√âpocas m√°x:** {tc['epochs']}")
            st.info(f"**Batch Size:** {tc['batch_size']}")
    
    # Mostrar configuraci√≥n detallada de entrenamiento
    if 'training_config' in config:
        with st.expander("üîß Configuraci√≥n de Entrenamiento Utilizada"):
            tc = config['training_config']
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**Par√°metros de Optimizaci√≥n:**")
                st.write(f"- Learning Rate: {tc['learning_rate']}")
                st.write(f"- Batch Size: {tc['batch_size']}")
                st.write(f"- √âpocas m√°ximas: {tc['epochs']}")
            
            with col2:
                st.write("**Control de Parada:**")
                st.write(f"- Early Stopping: {'‚úÖ Activado' if tc['use_early_stopping'] else '‚ùå Desactivado'}")
                if tc['use_early_stopping']:
                    st.write(f"- Paciencia ES: {tc['early_stopping_patience']}")
                st.write(f"- Paciencia Reduce LR: {tc['reduce_lr_patience']}")
            
            with col3:
                st.write("**Resultados del Entrenamiento:**")
                if 'debug_info' in metrics and 'training_epochs' in metrics['debug_info']:
                    debug = metrics['debug_info']
                    st.write(f"- √âpocas entrenadas: {debug['training_epochs']}")
                    st.write(f"- P√©rdida final train: {debug['final_train_loss']:.4f}")
                    st.write(f"- P√©rdida final val: {debug['final_val_loss']:.4f}")
                    
                    # Determinar si se activ√≥ early stopping
                    if tc['use_early_stopping'] and debug['training_epochs'] < tc['epochs']:
                        st.write("- ‚èπÔ∏è Early stopping activado")
                    elif debug['training_epochs'] == tc['epochs']:
                        st.write("- üèÅ √âpocas m√°ximas alcanzadas")
    
    # Mostrar m√©tricas
    show_model_metrics(metrics)
    
    # Mostrar historia del entrenamiento
    st.subheader("üìà Historia del Entrenamiento")
    show_training_history(history)
    
    # Mostrar predicciones con incertidumbre
    show_uncertainty_predictions(test_data, metrics)
    
    # An√°lisis de incertidumbre
    st.subheader("üîç An√°lisis de Incertidumbre")
    show_uncertainty_histogram(metrics)
    
    # Informaci√≥n adicional
    with st.expander(" Informaci√≥n Adicional"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**M√©tricas de Calibraci√≥n:**")
            st.write(f"- Cobertura IC 95%: {metrics['coverage_95']:.1%}")
            st.write(f"- Ancho promedio IC: {metrics['interval_width']:.2f} ¬µg/m¬≥")
            st.write(f"- Incertidumbre media: {metrics['mean_uncertainty']:.2f} ¬µg/m¬≥")
        
        with col2:
            st.markdown("**Configuraci√≥n del Modelo:**")
            st.write(f"- Arquitectura: {MODEL_CONFIGS[config['model_type']]['description']}")
        
        # Debug de cobertura
        if 'debug_info' in metrics:
            st.markdown("---")
            st.markdown("**üîç Debug - Informaci√≥n de Cobertura:**")
            debug = metrics['debug_info']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"**Muestras totales:** {debug['n_samples']}")
                st.write(f"**Dentro del IC:** {debug['n_within_ci']}")
                st.write(f"**Cobertura:** {debug['n_within_ci']/debug['n_samples']:.1%}")
            
            with col2:
                st.write(f"**Rango valores reales:** {debug['y_test_range'][0]:.1f} - {debug['y_test_range'][1]:.1f}")
                st.write(f"**Rango predicciones:** {debug['pred_mean_range'][0]:.1f} - {debug['pred_mean_range'][1]:.1f}")
                st.write(f"**Ancho medio IC:** {debug['mean_ci_width']:.2f}")
            
            with col3:
                st.write(f"**Rango incertidumbre:** {debug['pred_std_range'][0]:.3f} - {debug['pred_std_range'][1]:.3f}")
                st.write(f"**IC inferior:** {debug['ci_lower_range'][0]:.1f} - {debug['ci_lower_range'][1]:.1f}")
                st.write(f"**IC superior:** {debug['ci_upper_range'][0]:.1f} - {debug['ci_upper_range'][1]:.1f}")
            
            # Mostrar algunos ejemplos espec√≠ficos
            st.markdown("**üìã Ejemplos de predicciones:**")
            examples_df = pd.DataFrame({
                'Real': metrics['y_true'][:10],
                'Predicci√≥n': metrics['predictions_mean'][:10],
                'Incertidumbre': metrics['predictions_std'][:10],
                'IC_inferior': metrics['ci_lower'][:10],
                'IC_superior': metrics['ci_upper'][:10],
                'Dentro_IC': ((metrics['y_true'][:10] >= metrics['ci_lower'][:10]) & 
                             (metrics['y_true'][:10] <= metrics['ci_upper'][:10]))
            })
            st.dataframe(examples_df.round(2), use_container_width=True)


def show_data_summary(df: pd.DataFrame):
    """Muestra un resumen de los datos cargados."""
    
    # Gr√°fico de series temporales
    st.subheader("Serie Temporal de NO‚ÇÇ")
    
    # Agregaci√≥n diaria
    daily_data = df.groupby(df['fecha'].dt.date)['no2_value'].agg(['mean', 'std']).reset_index()
    daily_data['fecha'] = pd.to_datetime(daily_data['fecha'])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=daily_data['fecha'],
        y=daily_data['mean'],
        mode='lines',
        name='Promedio Diario',
        line=dict(color='blue')
    ))
    
    fig.update_layout(
        title='Evoluci√≥n Temporal del NO‚ÇÇ (Promedio Diario)',
        xaxis_title='Fecha',
        yaxis_title='Concentraci√≥n NO‚ÇÇ (¬µg/m¬≥)',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True) 


class BayesianUnifiedNowcaster:
    """Clase unificada para nowcasting bayesiano individual y global."""
    
    def __init__(self):
        self.df_master = None
        self.individual_nowcaster = BayesianNowcaster()
        self._initialize_session_state()
    
    def _initialize_session_state(self):
        """Inicializa el estado de la sesi√≥n."""
        if 'bnn_unified_data_loaded' not in st.session_state:
            st.session_state.bnn_unified_data_loaded = False
        if 'bnn_unified_mode' not in st.session_state:
            st.session_state.bnn_unified_mode = 'individual'
    
    @st.cache_data(ttl=3600)
    def load_data(_self) -> pd.DataFrame:
        """Carga y preprocesa los datos con cach√©."""
        try:
            # Usar el nuevo dataset con todas las caracter√≠sticas engineered
            df = pd.read_parquet('data/super_processed/7_4_no2_with_traffic_and_1meteo_and_1trafic_id.parquet')
            df['fecha'] = pd.to_datetime(df['fecha'])
            return df
        except Exception as e:
            st.error(f"Error al cargar los datos: {str(e)}")
            return pd.DataFrame()
    
    def show_data_overview(self):
        """Muestra overview del dataset completo."""
        st.header(" Overview del Dataset")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total registros", f"{len(self.df_master):,}")
        with col2:
            st.metric("Sensores NO‚ÇÇ", self.df_master['id_no2'].nunique())
        with col3:
            st.metric("Sensores tr√°fico", self.df_master['id_trafico'].nunique())
        with col4:
            periodo_a√±os = (self.df_master['fecha'].max() - self.df_master['fecha'].min()).days / 365.25
            st.metric("Per√≠odo", f"{periodo_a√±os:.1f} a√±os")
        
        # Mostrar distribuci√≥n por sensor
        with st.expander("üìã Distribuci√≥n de Datos por Sensor"):
            sensor_stats = self.df_master.groupby('id_no2').agg({
                'fecha': ['min', 'max', 'count'],
                'no2_value': ['mean', 'std']
            }).round(2)
            sensor_stats.columns = ['fecha_min', 'fecha_max', 'registros', 'no2_mean', 'no2_std']
            st.dataframe(sensor_stats, use_container_width=True)


def show_individual_bayesian_training():
    """Interfaz optimizada para entrenamiento de modelos bayesianos individuales."""
    
    # Crear instancia del nowcaster
    nowcaster = BayesianNowcaster()
    
    # Cargar datos
    if not st.session_state.bnn_data_loaded:
        #if st.button("üîÑ Cargar datos para Nowcasting Bayesiano Individual", type="primary", key="individual_load_data"):
        with st.spinner("Cargando datos..."):
            nowcaster.df_master = nowcaster.load_data()
            if not nowcaster.df_master.empty:
                st.session_state.bnn_data_loaded = True
                st.success("‚úÖ Datos cargados correctamente")
                st.rerun()
        return
    
    # Recuperar datos
    nowcaster.df_master = nowcaster.load_data()
    
    if nowcaster.df_master.empty:
        st.error("No se pudieron cargar los datos.")
        return
    
    # ==================== CONFIGURACI√ìN B√ÅSICA ====================
    st.markdown("###  Configuraci√≥n del Nowcasting Individual")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Selecci√≥n de sensor
        sensores = sorted(nowcaster.df_master['id_no2'].unique())
        sensor_seleccionado = st.selectbox(
            "Sensor de NO‚ÇÇ", 
            sensores, 
            index=2 if len(sensores) > 2 else 0,
            key="individual_sensor_selection"
        )
        
        # Filtrar por sensor
        df_sensor = nowcaster.df_master[nowcaster.df_master['id_no2'] == sensor_seleccionado]
        
        # Fechas disponibles
        fecha_min = df_sensor["fecha"].min().date()
        fecha_max = df_sensor["fecha"].max().date()
        
        # Fecha de divisi√≥n
        fecha_division = st.date_input(
            "Fecha de divisi√≥n (entrenamiento/evaluaci√≥n)",
            value=pd.to_datetime('2024-01-01').date(),
            min_value=fecha_min,
            max_value=fecha_max,
            help="Los datos anteriores se usan para entrenamiento, posteriores para evaluaci√≥n",
            key="individual_split_date"
        )
    
    with col2:
        # Configuraci√≥n del modelo
        model_type = st.selectbox(
            "Arquitectura del modelo",
            options=list(MODEL_CONFIGS.keys()),
            format_func=lambda x: MODEL_CONFIGS[x]['name'],
            help="Selecciona la complejidad del modelo bayesiano",
            key="individual_model_architecture"
        )
        
        # Mostrar descripci√≥n del modelo
        st.info(f"üìã **{MODEL_CONFIGS[model_type]['name']}**: {MODEL_CONFIGS[model_type]['description']}")
    
    # ==================== SELECCI√ìN DE VARIABLES (REUTILIZABLE) ====================
    selected_features = show_variable_selection(nowcaster.df_master, key_prefix="individual_")
    
    if not selected_features:
        st.warning("Selecciona al menos una variable para continuar.")
        return
    
    nowcaster.selected_features = selected_features
    
    # ==================== CONFIGURACI√ìN DE ENTRENAMIENTO (REUTILIZABLE) ====================
    training_config = show_training_configuration(key_prefix="individual_")
    
    # ==================== RESUMEN DE CONFIGURACI√ìN (REUTILIZABLE) ====================
    #ion_summary(sensor_seleccionado, selected_features, model_type, fecha_division)
    
    # ==================== PREPARAR DATOS (REUTILIZABLE) ====================
    result = prepare_training_data(df_sensor, selected_features, fecha_division)
    if result[0] is None:  # Error en preparaci√≥n
        return
    
    df_clean, train_data, test_data = result
    
    # ==================== INFORMACI√ìN DEL CONJUNTO DE DATOS (REUTILIZABLE) ====================
    show_dataset_info(df_clean, train_data, test_data, selected_features)
    
    # ==================== BOTONES DE ACCI√ìN ====================
    config_key = f"individual_{sensor_seleccionado}_{model_type}_{len(selected_features)}"
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.session_state.get('individual_bnn_model_trained', False) and st.session_state.get('individual_bnn_config_key') == config_key:
            analyze_button = st.button("Ver Resultados del Modelo", type="primary", key="individual_analyze_btn")
        else:
            analyze_button = False
            if st.session_state.get('individual_bnn_model_trained', False):
                st.info("Configuraci√≥n cambiada - Entrena un nuevo modelo")
            else:
                st.info("No existe un modelo entrenado con esta configuraci√≥n")
    
    with col2:
        train_button = st.button("Entrenar Modelo Bayesiano Individual", type="secondary", key="individual_train_btn")
    
    # ==================== PROCESAR ACCIONES ====================
    if train_button:
        if len(selected_features) == 0:
            st.error("‚ùå Selecciona al menos un grupo de variables")
        else:
            st.session_state.individual_bnn_config_key = config_key
            st.session_state.individual_bnn_show_results = False
            train_individual_bayesian_model(
                nowcaster, train_data, test_data, model_type, sensor_seleccionado,
                training_config
            )
    
    elif analyze_button and st.session_state.get('individual_bnn_model_trained', False):
        st.session_state.individual_bnn_show_results = True
    
    # ==================== MOSTRAR RESULTADOS (REUTILIZABLE) ====================
    if st.session_state.get('individual_bnn_show_results', False) and st.session_state.get('individual_bnn_model_trained', False):
        show_individual_model_results()
    
    # Si no se ha entrenado un modelo, mostrar resumen de datos
    elif not st.session_state.get('individual_bnn_model_trained', False):
        show_data_summary(df_clean)


def train_individual_bayesian_model(nowcaster, train_data, test_data, model_type, sensor_id, training_config):
    """Entrena el modelo bayesiano individual con configuraci√≥n personalizable."""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üîÑ Preparando datos...")
        progress_bar.progress(20)
        
        # Preparar datos (ahora son arrays 2D: [samples, features])
        X_train, y_train = nowcaster.prepare_nowcasting_data(train_data, nowcaster.selected_features)
        X_test, y_test = nowcaster.prepare_nowcasting_data(test_data, nowcaster.selected_features)
        
        if len(X_train) == 0 or len(X_test) == 0:
            st.error("‚ùå No se pudieron preparar suficientes datos")
            return
        
        st.write(f" **Datos preparados:**")
        st.write(f"- Entrenamiento: {X_train.shape}")
        st.write(f"- Evaluaci√≥n: {X_test.shape}")
        st.write(f"- Caracter√≠sticas: {len(nowcaster.selected_features)}")
        
        # Divisi√≥n de validaci√≥n temporal (80% train, 20% val)
        val_split = int(0.8 * len(X_train))
        X_val = X_train[val_split:]
        y_val = y_train[val_split:]
        X_train = X_train[:val_split]
        y_train = y_train[:val_split]
        
        st.write(f" **Divisi√≥n de datos:**")
        st.write(f"- Entrenamiento final: {X_train.shape[0]} muestras")
        st.write(f"- Validaci√≥n: {X_val.shape[0]} muestras")
        st.write(f"- Prueba: {X_test.shape[0]} muestras")
        
        status_text.text("üîÑ Normalizando datos...")
        progress_bar.progress(30)
        
        # Normalizar datos con verificaci√≥n
        nowcaster.scaler_X = StandardScaler()
        X_train_scaled = nowcaster.scaler_X.fit_transform(X_train)
        X_val_scaled = nowcaster.scaler_X.transform(X_val)
        X_test_scaled = nowcaster.scaler_X.transform(X_test)
        
        nowcaster.scaler_y = StandardScaler()
        y_train_scaled = nowcaster.scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
        y_val_scaled = nowcaster.scaler_y.transform(y_val.reshape(-1, 1)).flatten()
        
        status_text.text("üîÑ Creando modelo...")
        progress_bar.progress(40)
        
        # Crear y compilar modelo
        nowcaster.model = nowcaster.create_bayesian_model(X_train_scaled.shape[1], model_type)
        nowcaster.model = nowcaster.compile_model(nowcaster.model, learning_rate=training_config['learning_rate'])
        
        st.write(f"üß† **Modelo creado:**")
        st.write(f"- Input shape: {X_train_scaled.shape[1]}")
        st.write(f"- Arquitectura: {MODEL_CONFIGS[model_type]['name']}")
        st.write(f"- Par√°metros totales: {nowcaster.model.count_params():,}")
        
        status_text.text("Entrenando modelo...")
        progress_bar.progress(50)
        
        # Entrenar modelo con configuraci√≥n personalizada
        history = nowcaster.train_model(
            X_train_scaled, y_train_scaled,
            X_val_scaled, y_val_scaled,
            epochs=training_config['epochs'],
            batch_size=training_config['batch_size'],
            learning_rate=training_config['learning_rate'],
            use_early_stopping=training_config['use_early_stopping'],
            early_stopping_patience=training_config['early_stopping_patience'],
            reduce_lr_patience=training_config['reduce_lr_patience']
        )
        
        status_text.text(" Evaluando modelo...")
        progress_bar.progress(90)
        
        # Evaluar modelo - IMPORTANTE: usar datos desnormalizados para m√©tricas finales
        y_pred_mean_scaled, y_pred_std_scaled = nowcaster.predict_with_uncertainty(
            X_test_scaled, n_samples=100
        )
        
        # Desnormalizar predicciones
        y_pred_mean = nowcaster.scaler_y.inverse_transform(
            y_pred_mean_scaled.reshape(-1, 1)
        ).flatten()
        
        # Para la desviaci√≥n est√°ndar, escalar por la std del scaler
        y_pred_std = y_pred_std_scaled.flatten() * nowcaster.scaler_y.scale_[0]
        
        # Calcular intervalos de confianza desnormalizados
        ci_lower = y_pred_mean - 1.96 * y_pred_std
        ci_upper = y_pred_mean + 1.96 * y_pred_std
        
        # Calcular m√©tricas con datos desnormalizados
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        within_ci = (y_test >= ci_lower) & (y_test <= ci_upper)
        coverage_95 = np.mean(within_ci)
        mean_uncertainty = np.mean(y_pred_std)
        interval_width = np.mean(ci_upper - ci_lower)
        
        metrics = {
            'mse': mean_squared_error(y_test, y_pred_mean),
            'mae': mean_absolute_error(y_test, y_pred_mean),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_mean)),
            'r2': r2_score(y_test, y_pred_mean),
            'mean_uncertainty': mean_uncertainty,
            'coverage_95': coverage_95,
            'interval_width': interval_width,
            'predictions_mean': y_pred_mean,
            'predictions_std': y_pred_std,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'y_true': y_test
        }
        
        # Guardar resultados en session state
        st.session_state.individual_bnn_model_trained = True
        st.session_state.individual_bnn_metrics = metrics
        st.session_state.individual_bnn_history = history
        st.session_state.individual_bnn_test_data = test_data.iloc[-len(y_test):].copy()
        st.session_state.individual_bnn_config = {
            'model_type': model_type,
            'features': nowcaster.selected_features,
            'sensor_id': sensor_id,
            'training_config': training_config
        }
        st.session_state.individual_bnn_show_results = True
        
        progress_bar.progress(100)
        status_text.text("‚úÖ Modelo entrenado correctamente!")
        
        st.success("üéâ ¬°Modelo bayesiano individual entrenado exitosamente!")
        
        # Mostrar resultados autom√°ticamente
        time.sleep(1)
        st.rerun()
        
    except Exception as e:
        import traceback
        st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
        st.error(f"üìã Detalles del error: {traceback.format_exc()}")
        progress_bar.empty()
        status_text.empty()


def show_individual_model_results():
    """Muestra los resultados del modelo bayesiano individual usando funciones reutilizables."""
    
    if 'individual_bnn_metrics' not in st.session_state:
        st.error("‚ùå No hay resultados de modelo individual disponibles")
        return
    
    metrics = st.session_state.individual_bnn_metrics
    history = st.session_state.individual_bnn_history
    test_data = st.session_state.individual_bnn_test_data
    config = st.session_state.individual_bnn_config
    
    # Usar funci√≥n reutilizable para mostrar resultados completos
    show_complete_model_results(
        metrics, history, test_data, config, 
        title="Resultados del Modelo Bayesiano Individual"
    )


def show_global_bayesian_training(unified_nowcaster):
    """Interfaz optimizada para entrenamiento de modelos bayesianos globales."""
    st.subheader("Nowcasting Bayesiano Global Multi-Sensor")
    
    # ==================== CONFIGURACI√ìN DE SENSORES ====================
    st.markdown("### üì° Configuraci√≥n de Sensores")
    
    sensores_disponibles = sorted(unified_nowcaster.df_master['id_no2'].unique())
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Sensores para Entrenamiento**")
        sensores_train = st.multiselect(
            "Selecciona sensores para entrenar:",
            sensores_disponibles,
            default=sensores_disponibles[:-2],  # Todos menos los √∫ltimos 2
            key="global_bnn_train_sensors"
        )
    
    with col2:
        st.markdown("**Sensores para Evaluaci√≥n**")
        sensores_test = st.multiselect(
            "Selecciona sensores para evaluar:",
            sensores_disponibles,
            default=sensores_disponibles[-2:],  # Los √∫ltimos 2
            key="global_bnn_test_sensors"
        )
    
    # Validaciones
    if not sensores_train:
        st.warning("‚ö†Ô∏è Selecciona al menos un sensor para entrenamiento")
        return
    
    if not sensores_test:
        st.warning("‚ö†Ô∏è Selecciona al menos un sensor para evaluaci√≥n")
        return
    
    # Estad√≠sticas de la configuraci√≥n
    df_train = unified_nowcaster.df_master[unified_nowcaster.df_master['id_no2'].isin(sensores_train)]
    df_test = unified_nowcaster.df_master[unified_nowcaster.df_master['id_no2'].isin(sensores_test)]
    
    st.markdown("###  Estad√≠sticas de la Configuraci√≥n")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Sensores entrenamiento", len(sensores_train))
    with col2:
        st.metric("Registros entrenamiento", f"{len(df_train):,}")
    with col3:
        st.metric("Sensores evaluaci√≥n", len(sensores_test))
    with col4:
        st.metric("Registros evaluaci√≥n", f"{len(df_test):,}")
    
    # ==================== CONFIGURACI√ìN B√ÅSICA ====================
    col1, col2 = st.columns(2)
    
    with col1:
        model_type = st.selectbox(
            "Arquitectura del modelo",
            options=list(MODEL_CONFIGS.keys()),
            format_func=lambda x: MODEL_CONFIGS[x]['name'],
            help="Selecciona la complejidad del modelo bayesiano",
            key="global_bnn_model_architecture"
        )
    
    with col2:
        fecha_division = st.date_input(
            "Fecha de divisi√≥n temporal",
            value=pd.to_datetime('2024-01-01').date(),
            key="global_bnn_split_date"
        )
    
    # ==================== SELECCI√ìN DE VARIABLES (REUTILIZABLE) ====================
    selected_features = show_variable_selection(unified_nowcaster.df_master, key_prefix="global_")
    
    if not selected_features:
        st.warning("‚ö†Ô∏è No hay variables disponibles. Verifica los datos.")
        return
    
    # Validar que tenemos features suficientes
    if len(selected_features) < 5:
        st.error(f"‚ùå Muy pocas variables disponibles: {len(selected_features)}")
        return
    
    # ==================== CONFIGURACI√ìN DE ENTRENAMIENTO (REUTILIZABLE) ====================
    training_config = show_training_configuration(key_prefix="global_")
    
    # ==================== RESUMEN DE CONFIGURACI√ìN ====================
    additional_info = {
        "Sensores entrenamiento": f"{len(sensores_train)} sensores",
        "Sensores evaluaci√≥n": f"{len(sensores_test)} sensores",
        "Modo": "Modelo Global Multi-Sensor"
    }
    
    
    # ==================== BOTONES DE ACCI√ìN ====================
    #col1, col2 = st.columns(2)
    
    #with col1:
    if st.button("Entrenar Modelo Bayesiano Global", type="primary", key="global_train_btn"):
        train_global_bayesian_model(
            unified_nowcaster, sensores_train, sensores_test, 
            selected_features, model_type, fecha_division, training_config
        )
    
    # ==================== MOSTRAR RESULTADOS EXISTENTES ====================
    if 'global_bnn_model_results' in st.session_state:
        results = st.session_state.global_bnn_model_results
        
        st.divider()
        st.subheader(" Resultados del Modelo Bayesiano Global")
        
        # Mostrar m√©tricas globales
        st.markdown("### üìà M√©tricas Globales")
        show_model_metrics(results['metrics'])
        
        # Mostrar an√°lisis por sensor
        show_global_bayesian_sensor_analysis(
            results['test_df'], 
            results['model'], 
            results['selected_features'], 
            results['scaler_X'],
            results['scaler_y'],
            results['sensores_test']
        )


def train_global_bayesian_model(unified_nowcaster, sensores_train, sensores_test, 
                               selected_features, model_type, fecha_division, training_config):
    """Entrena un modelo bayesiano global con la configuraci√≥n especificada."""
    
    with st.spinner("Entrenando modelo bayesiano global..."):
        # Limpiar contexto de TensorFlow para evitar conflictos
        try:
            tf.keras.backend.clear_session()
            tf.compat.v1.reset_default_graph()
        except:
            pass  # Ignorar errores de limpieza
        
        # Preparar datos
        df_train = unified_nowcaster.df_master[unified_nowcaster.df_master['id_no2'].isin(sensores_train)]
        df_test = unified_nowcaster.df_master[unified_nowcaster.df_master['id_no2'].isin(sensores_test)]
        
        # VALIDAR QUE TODAS LAS FEATURES EXISTEN
        missing_features_train = [f for f in selected_features if f not in df_train.columns]
        missing_features_test = [f for f in selected_features if f not in df_test.columns]
        
        if missing_features_train or missing_features_test:
            st.error(f"‚ùå Features faltantes en train: {missing_features_train}")
            st.error(f"‚ùå Features faltantes en test: {missing_features_test}")
            return
        
        # Divisi√≥n temporal adicional
        fecha_division_dt = pd.to_datetime(fecha_division)
        df_train = df_train[df_train['fecha'] <= fecha_division_dt]
        df_test = df_test[df_test['fecha'] > fecha_division_dt]
        
        # Preparar datos para nowcasting SIN DATA LEAKAGE
        X_train, y_train = unified_nowcaster.individual_nowcaster.prepare_nowcasting_data(df_train, selected_features)
        X_test, y_test = unified_nowcaster.individual_nowcaster.prepare_nowcasting_data(df_test, selected_features)
        
        # Validar que tenemos datos suficientes
        if len(X_train) < 500 or len(X_test) < 100:
            st.error("‚ùå No hay datos suficientes despu√©s de la limpieza")
            return
        
        # Divisi√≥n de validaci√≥n temporal (80% train, 20% val)
        val_split = int(0.8 * len(X_train))
        X_val = X_train[val_split:]
        y_val = y_train[val_split:]
        X_train = X_train[:val_split]
        y_train = y_train[:val_split]
        
        # ESCALADO SIN DATA LEAKAGE - Solo usar X_train para fit
        scaler_X = StandardScaler()
        X_train_scaled = scaler_X.fit_transform(X_train)  # FIT solo con entrenamiento
        X_val_scaled = scaler_X.transform(X_val)          # TRANSFORM validaci√≥n
        X_test_scaled = scaler_X.transform(X_test)        # TRANSFORM test
        
        scaler_y = StandardScaler()
        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()  # FIT solo con entrenamiento
        y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()          # TRANSFORM validaci√≥n
        
        # Crear y compilar modelo
        nowcaster = BayesianNowcaster()
        nowcaster.model = nowcaster.create_bayesian_model(X_train_scaled.shape[1], model_type)
        nowcaster.model = nowcaster.compile_model(nowcaster.model, learning_rate=training_config['learning_rate'])
        nowcaster.scaler_X = scaler_X
        nowcaster.scaler_y = scaler_y
        
        # Entrenar modelo
        history = nowcaster.train_model(
            X_train_scaled, y_train_scaled,
            X_val_scaled, y_val_scaled,
            epochs=training_config['epochs'],
            batch_size=training_config['batch_size'],
            learning_rate=training_config['learning_rate'],
            use_early_stopping=training_config['use_early_stopping'],
            early_stopping_patience=training_config['early_stopping_patience'],
            reduce_lr_patience=training_config['reduce_lr_patience']
        )
        
        # CORREGIR: Evaluar modelo global con datos correctamente escalados
        # El problema era que se pasaba y_test sin escalar pero X_test escalado
        y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
        metrics = nowcaster.evaluate_model(X_test_scaled, y_test_scaled, n_samples=100)
        
        # IMPORTANTE: Desnormalizar las predicciones en metrics para visualizaci√≥n
        # Las m√©tricas internas est√°n en escala normalizada, necesitamos desnormalizarlas
        metrics_denormalized = {
            'mse': metrics['mse'] * (scaler_y.scale_[0] ** 2),  # MSE se escala por œÉ¬≤
            'mae': metrics['mae'] * scaler_y.scale_[0],         # MAE se escala por œÉ
            'rmse': metrics['rmse'] * scaler_y.scale_[0],       # RMSE se escala por œÉ
            'r2': metrics['r2'],  # R¬≤ es invariante al escalado
            'mean_uncertainty': metrics['mean_uncertainty'] * scaler_y.scale_[0],
            'coverage_95': metrics['coverage_95'],  # Cobertura es invariante
            'interval_width': metrics['interval_width'] * scaler_y.scale_[0],
            'predictions_mean': scaler_y.inverse_transform(metrics['predictions_mean'].reshape(-1, 1)).flatten(),
            'predictions_std': metrics['predictions_std'] * scaler_y.scale_[0],
            'ci_lower': scaler_y.inverse_transform(metrics['ci_lower'].reshape(-1, 1)).flatten(),
            'ci_upper': scaler_y.inverse_transform(metrics['ci_upper'].reshape(-1, 1)).flatten(),
            'y_true': y_test,  # Valores reales sin escalar
            'debug_info': {
                **metrics['debug_info'],
                'scaling_applied': True,
                'scaler_mean': float(scaler_y.mean_[0]),
                'scaler_scale': float(scaler_y.scale_[0])
            }
        }
        
        # Guardar resultados en session_state
        st.session_state.global_bnn_model_results = {
            'model': nowcaster.model,
            'metrics': metrics_denormalized,  # Usar m√©tricas desnormalizadas
            'history': history,
            'test_df': df_test,
            'sensores_train': sensores_train,
            'sensores_test': sensores_test,
            'scaler_X': scaler_X,
            'scaler_y': scaler_y,
            'selected_features': selected_features,
            'model_type': model_type,
            'training_config': training_config
        }
        
        st.success("‚úÖ Modelo bayesiano global entrenado exitosamente!")
        st.info(" Los resultados se muestran a continuaci√≥n...")
        
        # AGREGAR: Verificaci√≥n de m√©tricas para debug
        st.write(f"üîç **Verificaci√≥n de m√©tricas:**")
        st.write(f"- RMSE global (desnormalizado): {metrics_denormalized['rmse']:.2f} ¬µg/m¬≥")
        st.write(f"- RMSE global (normalizado): {metrics['rmse']:.3f}")
        st.write(f"- R¬≤ global: {metrics_denormalized['r2']:.3f}")
        st.write(f"- Cobertura IC 95%: {metrics_denormalized['coverage_95']:.1%}")
        st.write(f"- Predicciones desnormalizadas rango: [{metrics_denormalized['predictions_mean'].min():.2f}, {metrics_denormalized['predictions_mean'].max():.2f}]")
        st.write(f"- Valores reales rango: [{y_test.min():.2f}, {y_test.max():.2f}]")
        
        # AGREGAR: Validaci√≥n completa de data leakage
        st.markdown("---")
        st.markdown("### üîç Metodolog√≠a de Divisi√≥n de Datos")
        
        # Calcular tama√±os originales antes de divisi√≥n de validaci√≥n
        original_train_size = len(X_train) + len(X_val)
        
        st.info(f"""
        ** Divisi√≥n de datos aplicada:**
        - **Datos originales**: {original_train_size} muestras de entrenamiento, {X_test.shape[0]} de evaluaci√≥n
        - **Divisi√≥n temporal**: Datos antes/despu√©s de {fecha_division}
        - **Divisi√≥n de validaci√≥n**: 80% entrenamiento ({X_train.shape[0]} muestras), 20% validaci√≥n ({X_val.shape[0]} muestras)
        - **Escalado**: Ajustado SOLO con los {X_train.shape[0]} muestras de entrenamiento final
        
        **‚úÖ Metodolog√≠a correcta:**
        - Los scalers se ajustan SOLO con el conjunto de entrenamiento final
        - Los datos de validaci√≥n y test se transforman (NO se usan para ajustar)
        - No hay data leakage temporal ni de validaci√≥n cruzada
        """)
        
        
        # Mostrar resumen final
        st.markdown("---")
        st.markdown("###  Resumen del Entrenamiento")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.success(f"""
            **‚úÖ Modelo Entrenado**
            - Arquitectura: {MODEL_CONFIGS[model_type]['name']}
            - Par√°metros: {nowcaster.model.count_params():,}
            - Sensores train: {len(sensores_train)}
            - Sensores test: {len(sensores_test)}
            """)
        
        with col2:
            st.info(f"""
            ** Datos Utilizados**
            - Train final: {X_train.shape[0]:,} muestras
            - Validaci√≥n: {X_val.shape[0]:,} muestras  
            - Evaluaci√≥n: {X_test.shape[0]:,} muestras
            - Caracter√≠sticas: {len(selected_features)}
            """)
        
        with col3:
            st.metric(
                "RMSE Global", 
                f"{metrics_denormalized['rmse']:.2f} ¬µg/m¬≥",
                help="Error cuadr√°tico medio en escala original"
            )
            st.metric(
                "R¬≤ Global",
                f"{metrics_denormalized['r2']:.3f}",
                help="Coeficiente de determinaci√≥n"
            )


def show_global_bayesian_sensor_analysis(test_df, model, selected_features, scaler_X, scaler_y, sensores_test):
    """Muestra an√°lisis detallado por sensor para el modelo bayesiano global."""
    
    st.subheader(" An√°lisis por Sensor de Evaluaci√≥n")
    
    # Calcular m√©tricas por sensor
    sensor_metrics = []
    
    # Crear instancia local de nowcaster para prepare_nowcasting_data
    local_nowcaster = BayesianNowcaster()
    
    for sensor_id in sensores_test:
        sensor_data = test_df[test_df['id_no2'] == sensor_id].copy()
        
        if len(sensor_data) == 0:
            continue
        
        # Preparar datos del sensor espec√≠fico
        X_sensor, y_sensor = local_nowcaster.prepare_nowcasting_data(
            sensor_data, selected_features
        )
        
        if len(X_sensor) == 0:
            continue
        
        # APLICAR EL MISMO ESCALADO QUE EN EL ENTRENAMIENTO
        X_sensor_scaled = scaler_X.transform(X_sensor)
        
        # Predicciones con incertidumbre con manejo robusto de errores
        try:
            nowcaster = BayesianNowcaster()
            nowcaster.model = model
            
            # Validar que el modelo existe
            if nowcaster.model is None:
                st.warning(f"‚ö†Ô∏è Modelo no disponible para sensor {sensor_id}")
                continue
            
            # Intentar predicci√≥n con manejo de errores
            y_pred_mean_scaled, y_pred_std_scaled = nowcaster.predict_with_uncertainty(
                X_sensor_scaled, n_samples=50  # Reducir samples para evitar problemas
            )
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error al procesar sensor {sensor_id}: {str(e)}")
            st.info("Intentando con predicci√≥n est√°ndar como fallback...")
            
            try:
                # Fallback: predicci√≥n est√°ndar sin Monte Carlo
                nowcaster = BayesianNowcaster()
                nowcaster.model = model
                y_pred_mean_scaled = model(X_sensor_scaled, training=False).numpy()
                y_pred_std_scaled = np.ones_like(y_pred_mean_scaled) * 0.1  # Incertidumbre m√≠nima
            except Exception as e2:
                st.error(f"‚ùå Error cr√≠tico con sensor {sensor_id}: {str(e2)}")
                continue
        
        # Desnormalizar predicciones
        y_pred_mean = scaler_y.inverse_transform(y_pred_mean_scaled.reshape(-1, 1)).flatten()
        y_pred_std = y_pred_std_scaled.flatten() * scaler_y.scale_[0]
        
        # M√©tricas
        rmse = np.sqrt(mean_squared_error(y_sensor, y_pred_mean))
        r2 = r2_score(y_sensor, y_pred_mean)
        mae = mean_absolute_error(y_sensor, y_pred_mean)
        
        # M√©tricas de incertidumbre
        ci_lower = y_pred_mean - 1.96 * y_pred_std
        ci_upper = y_pred_mean + 1.96 * y_pred_std
        within_ci = (y_sensor >= ci_lower) & (y_sensor <= ci_upper)
        coverage_95 = np.mean(within_ci)
        mean_uncertainty = np.mean(y_pred_std)
        
        sensor_metrics.append({
            'sensor_id': sensor_id,
            'n_samples': len(sensor_data),
            'rmse': rmse,
            'r2': r2,
            'mae': mae,
            'coverage_95': coverage_95,
            'mean_uncertainty': mean_uncertainty,
            'no2_mean': y_sensor.mean(),
            'no2_std': y_sensor.std()
        })
    
    sensor_metrics_df = pd.DataFrame(sensor_metrics)
    
    # Validar que tenemos m√©tricas
    if sensor_metrics_df.empty:
        st.error("‚ùå No se pudieron calcular m√©tricas por sensor")
        return
    
    # Mostrar m√©tricas resumidas en columnas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "RMSE Promedio",
            f"{sensor_metrics_df['rmse'].mean():.2f} ¬µg/m¬≥",
            f"¬±{sensor_metrics_df['rmse'].std():.2f}"
        )
    
    with col2:
        st.metric(
            "R¬≤ Promedio", 
            f"{sensor_metrics_df['r2'].mean():.3f}",
            f"¬±{sensor_metrics_df['r2'].std():.3f}"
        )
    
    with col3:
        st.metric(
            "Cobertura IC 95%",
            f"{sensor_metrics_df['coverage_95'].mean():.1%}",
            f"¬±{sensor_metrics_df['coverage_95'].std():.1%}"
        )
    
    with col4:
        st.metric(
            "Incertidumbre Promedio",
            f"{sensor_metrics_df['mean_uncertainty'].mean():.2f} ¬µg/m¬≥",
            f"¬±{sensor_metrics_df['mean_uncertainty'].std():.2f}"
        )

    
    # Mostrar tabla de m√©tricas
    with st.expander("üìã M√©tricas Detalladas por Sensor"):
        st.dataframe(
            sensor_metrics_df.style.format({
                'rmse': '{:.2f}',
                'r2': '{:.3f}',
                'mae': '{:.2f}',
                'coverage_95': '{:.1%}',
                'mean_uncertainty': '{:.2f}',
                'no2_mean': '{:.2f}',
                'no2_std': '{:.2f}'
            }),
            use_container_width=True
        )
    
    # Selector para an√°lisis individual
    st.markdown("### üîç An√°lisis Detallado por Sensor")
    
    sensor_seleccionado = st.selectbox(
        "Selecciona sensor para an√°lisis detallado:",
        sensores_test,
        key="global_bnn_analysis_sensor"
    )
    
    # Usar checkbox en lugar de bot√≥n para evitar rerun
    if st.checkbox("üìà Mostrar An√°lisis Detallado", key="show_detailed_bnn_analysis"):
        show_detailed_bayesian_sensor_analysis(test_df, model, selected_features, scaler_X, scaler_y, sensor_seleccionado)


def show_detailed_bayesian_sensor_analysis(test_df, model, selected_features, scaler_X, scaler_y, sensor_id):
    """Muestra an√°lisis detallado para un sensor espec√≠fico."""
    
    sensor_data = test_df[test_df['id_no2'] == sensor_id].copy()
    
    if len(sensor_data) == 0:
        st.error(f"No hay datos para el sensor {sensor_id}")
        return
    
    # Preparar datos del sensor
    nowcaster = BayesianNowcaster()
    X_sensor, y_sensor = nowcaster.prepare_nowcasting_data(sensor_data, selected_features)
    
    if len(X_sensor) == 0:
        st.error(f"No se pudieron preparar datos para el sensor {sensor_id}")
        return
    
    # Aplicar escalado
    X_sensor_scaled = scaler_X.transform(X_sensor)
    
    # Predicciones con incertidumbre
    nowcaster.model = model
    y_pred_mean_scaled, y_pred_std_scaled = nowcaster.predict_with_uncertainty(
        X_sensor_scaled, n_samples=100
    )
    
    # Desnormalizar
    y_pred_mean = scaler_y.inverse_transform(y_pred_mean_scaled.reshape(-1, 1)).flatten()
    y_pred_std = y_pred_std_scaled.flatten() * scaler_y.scale_[0]
    
    st.subheader(f" An√°lisis Detallado - Sensor {sensor_id}")
    
    # M√©tricas
    rmse = np.sqrt(mean_squared_error(y_sensor, y_pred_mean))
    r2 = r2_score(y_sensor, y_pred_mean)
    mae = mean_absolute_error(y_sensor, y_pred_mean)
    
    # M√©tricas de incertidumbre
    ci_lower = y_pred_mean - 1.96 * y_pred_std
    ci_upper = y_pred_mean + 1.96 * y_pred_std
    within_ci = (y_sensor >= ci_lower) & (y_sensor <= ci_upper)
    coverage_95 = np.mean(within_ci)
    mean_uncertainty = np.mean(y_pred_std)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("RMSE", f"{rmse:.2f} ¬µg/m¬≥")
    with col2:
        st.metric("R¬≤", f"{r2:.3f}")
    with col3:
        st.metric("Cobertura IC 95%", f"{coverage_95:.1%}")
    with col4:
        st.metric("Incertidumbre Media", f"{mean_uncertainty:.2f} ¬µg/m¬≥")
    
    # Crear m√©tricas para visualizaci√≥n
    sensor_metrics = {
        'predictions_mean': y_pred_mean,
        'predictions_std': y_pred_std,
        'ci_lower': ci_lower,
        'ci_upper': ci_upper,
        'y_true': y_sensor
    }
    
    # Mostrar predicciones con incertidumbre
    show_uncertainty_predictions(sensor_data.iloc[-len(y_sensor):], sensor_metrics)


def show_bayesian_info_panel():
    """Muestra panel de informaci√≥n sobre el nowcasting bayesiano unificado."""
    with st.expander("‚ÑπÔ∏è Acerca del Nowcasting Bayesiano Unificado", expanded=False):
        st.markdown("""
        **üß† Nowcasting Bayesiano Unificado**
        
        Este m√≥dulo permite entrenar y comparar dos tipos de modelos bayesianos:
        
        **Modelos Individuales:**
        - Un modelo bayesiano por sensor
        - Especializado en patrones locales espec√≠ficos
        - Ideal para an√°lisis detallado por ubicaci√≥n
        - Cuantificaci√≥n de incertidumbre personalizada
        
        **Modelos Globales:**
        - Un modelo entrenado con m√∫ltiples sensores
        - Aprende patrones universales transferibles
        - Ideal para nowcasting en nuevas ubicaciones
        - Incertidumbre robusta multi-sensor
        
        **Configuraci√≥n Experimental:**
        - Selecciona sensores para entrenamiento vs evaluaci√≥n
        - Eval√∫a transferibilidad entre ubicaciones
        - An√°lisis detallado de incertidumbre por sensor
        - Monte Carlo Dropout para cuantificaci√≥n bayesiana
        
        **Ventajas del Enfoque Bayesiano:**
        - **Cuantificaci√≥n de incertidumbre**: Intervalos de confianza
        - **Robustez**: Manejo de datos ruidosos
        - **Transferibilidad**: Aplicable a ciudades sin sensores
        - **Interpretabilidad**: Confianza en las predicciones
        
        **‚ö†Ô∏è Nota importante:**
        Los modelos NO utilizan valores hist√≥ricos de NO‚ÇÇ, permitiendo su 
        aplicaci√≥n directa a ciudades sin sensores de calidad del aire.
        """)


# ==================== FUNCI√ìN PRINCIPAL UNIFICADA ====================

def bayesian_nowcasting_page():
    """Funci√≥n principal unificada para la p√°gina de nowcasting bayesiano."""
        
    # Panel de informaci√≥n
    show_bayesian_info_panel()
    
    # Inicializar trainer unificado
    unified_nowcaster = BayesianUnifiedNowcaster()
    
    # Cargar datos
    if not st.session_state.bnn_unified_data_loaded:
        if st.button(" Cargar Dataset Completo", type="primary", key="unified_bnn_load_data"):
            with st.spinner("Cargando dataset completo..."):
                unified_nowcaster.df_master = unified_nowcaster.load_data()
                if not unified_nowcaster.df_master.empty:
                    st.session_state.bnn_unified_data_loaded = True
                    st.success("¬°Dataset cargado exitosamente!")
                    st.rerun()
        return
    
    # Recuperar datos
    unified_nowcaster.df_master = unified_nowcaster.load_data()
    
    if unified_nowcaster.df_master.empty:
        st.error("No se pudieron cargar los datos.")
        return
    
    # Mostrar overview
    unified_nowcaster.show_data_overview()
    
    # Selector de modo
    st.header(" Selecciona Tipo de Modelo")
    
    mode = st.radio(
        "Tipo de nowcasting:",
        ["Individual (por sensor)", "Global (multi-sensor)"],
        index=0 if st.session_state.bnn_unified_mode == 'individual' else 1,
        horizontal=True
    )
    
    # Actualizar estado
    if "Individual" in mode:
        st.session_state.bnn_unified_mode = 'individual'
    else:
        st.session_state.bnn_unified_mode = 'global'
    
    st.divider()
    
    # Mostrar interfaz seg√∫n el modo
    if st.session_state.bnn_unified_mode == 'individual':
        show_individual_bayesian_training()
    else:
        show_global_bayesian_training(unified_nowcaster)


# ==================== FUNCIONES ORIGINALES PRESERVADAS ====================

# Mantener todas las funciones originales para compatibilidad
def show_info_panel():
    """Mantener funci√≥n original para compatibilidad."""
    show_bayesian_info_panel()


# ==================== FUNCIONES REUTILIZABLES PARA CONFIGURACI√ìN ====================

def show_variable_selection(df_master, key_prefix=""):
    """Funci√≥n reutilizable para selecci√≥n de variables por categor√≠as."""
    st.markdown("### üîß Selecci√≥n de Variables")
    
    # Crear tabs para categor√≠as usando VARIABLE_CATEGORIES
    var_tabs = st.tabs(list(VARIABLE_CATEGORIES.keys()))
    
    selected_features = []
    for i, (category, vars_list) in enumerate(VARIABLE_CATEGORIES.items()):
        with var_tabs[i]:
            # Filtrar variables que existen en los datos
            available_vars = [var for var in vars_list if var in df_master.columns or 'sin' in var or 'cos' in var]
            
            # Configurar defaults - todas las variables disponibles
            default_vars = available_vars
            
            selected_in_category = st.multiselect(
                f"Variables de {category}",
                available_vars,
                default=default_vars,
                help=f"Selecciona las variables de {category.lower()} para el modelo",
                key=f"{key_prefix}vars_{category.replace(' ', '_').lower()}"
            )
            selected_features.extend(selected_in_category)
    
    return selected_features


def show_training_configuration(key_prefix=""):
    """Funci√≥n reutilizable para configuraci√≥n de entrenamiento."""
    st.markdown("### ‚öôÔ∏è Configuraci√≥n de Entrenamiento")
    
    # Crear dos columnas para los controles
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Par√°metros Principales**")
        
        # Learning Rate
        learning_rate = st.number_input(
            "Learning Rate",
            min_value=0.0001,
            max_value=0.1,
            value=0.01,
            step=0.001,
            format="%.4f",
            help="Tasa de aprendizaje del optimizador. Valores m√°s altos = convergencia m√°s r√°pida pero menos estable",
            key=f"{key_prefix}learning_rate"
        )
        
        # √âpocas
        epochs = st.number_input(
            "N√∫mero m√°ximo de √©pocas",
            min_value=10,
            max_value=500,
            value=150,
            step=10,
            help="N√∫mero m√°ximo de √©pocas de entrenamiento",
            key=f"{key_prefix}epochs"
        )
        
        # Batch Size
        batch_size = st.selectbox(
            "Batch Size",
            options=[16, 32, 64, 128, 256],
            index=2,  # 64 por defecto
            help="Tama√±o del lote para entrenamiento. Valores m√°s grandes = entrenamiento m√°s estable",
            key=f"{key_prefix}batch_size"
        )
    
    with col2:
        st.markdown("**üõë Control de Parada**")
        
        # Early Stopping
        use_early_stopping = st.checkbox(
            "Activar Early Stopping",
            value=True,
            help="Detener entrenamiento autom√°ticamente cuando no mejore la validaci√≥n",
            key=f"{key_prefix}early_stopping"
        )
        
        # Paciencia Early Stopping
        if use_early_stopping:
            early_stopping_patience = st.number_input(
                "Paciencia Early Stopping",
                min_value=5,
                max_value=50,
                value=25,
                step=5,
                help="N√∫mero de √©pocas sin mejora antes de detener el entrenamiento",
                key=f"{key_prefix}es_patience"
            )
        else:
            early_stopping_patience = 25
        
        # Paciencia Reduce LR
        reduce_lr_patience = st.number_input(
            "Paciencia Reduce LR",
            min_value=3,
            max_value=30,
            value=12,
            step=2,
            help="√âpocas sin mejora antes de reducir learning rate",
            key=f"{key_prefix}lr_patience"
        )
    
    # Crear configuraci√≥n de entrenamiento
    training_config = {
        'learning_rate': learning_rate,
        'batch_size': batch_size,
        'epochs': epochs,
        'use_early_stopping': use_early_stopping,
        'early_stopping_patience': early_stopping_patience,
        'reduce_lr_patience': reduce_lr_patience
    }
    
    # # Mostrar resumen de configuraci√≥n de entrenamiento
    # with st.expander("üìã Resumen de Configuraci√≥n de Entrenamiento"):
    #     col1, col2, col3 = st.columns(3)
        
    #     with col1:
    #         st.write("**Optimizaci√≥n:**")
    #         st.write(f"- Learning Rate: {learning_rate}")
    #         st.write(f"- Batch Size: {batch_size}")
    #         st.write(f"- √âpocas m√°x: {epochs}")
        
    #     with col2:
    #         st.write("**Control de Parada:**")
    #         st.write(f"- Early Stopping: {'‚úÖ' if use_early_stopping else '‚ùå'}")
    #         if use_early_stopping:
    #             st.write(f"- Paciencia ES: {early_stopping_patience}")
    #         st.write(f"- Paciencia LR: {reduce_lr_patience}")
        
    #     with col3:
    #         st.write("**Estimaci√≥n:**")
    #         if use_early_stopping:
    #             est_time = "5-30 min"
    #             est_epochs = f"20-{min(epochs, early_stopping_patience + 20)}"
    #         else:
    #             est_time = f"{epochs * 0.1:.0f}-{epochs * 0.3:.0f} min"
    #             est_epochs = str(epochs)
    #         st.write(f"- Tiempo estimado: {est_time}")
    #         st.write(f"- √âpocas esperadas: {est_epochs}")
    
    return training_config


def show_dataset_info(df_clean, train_data, test_data, selected_features):
    """Funci√≥n reutilizable para mostrar informaci√≥n del conjunto de datos."""
    st.markdown("### Informaci√≥n del Conjunto de Datos")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Registros totales", len(df_clean))
    with col2:
        st.metric("Entrenamiento", len(train_data))
    with col3:
        st.metric("Evaluaci√≥n", len(test_data))
    with col4:
        st.metric("Variables", len(selected_features))


def prepare_training_data(df_sensor, selected_features, fecha_division):
    """Funci√≥n reutilizable para preparar datos de entrenamiento."""
    with st.spinner("Preparando datos para entrenamiento..."):
        df_processed = df_sensor.copy()
        
        # Limpiar datos
        df_clean = df_processed.dropna(subset=selected_features + ['no2_value'])
        
        if len(df_clean) < 1000:
            st.error("‚ùå Datos insuficientes despu√©s de limpiar NaN")
            return None, None, None
        
        # Dividir datos temporalmente
        fecha_division_dt = pd.to_datetime(fecha_division)
        train_data = df_clean[df_clean['fecha'] <= fecha_division_dt]
        test_data = df_clean[df_clean['fecha'] > fecha_division_dt]
        
        if len(train_data) < 500 or len(test_data) < 100:
            st.error("‚ùå No hay suficientes datos para entrenamiento o evaluaci√≥n.")
            return None, None, None
    
    return df_clean, train_data, test_data


def show_model_configuration_summary(config):
    """Funci√≥n reutilizable para mostrar configuraci√≥n del modelo entrenado."""
    st.subheader("‚öôÔ∏è Configuraci√≥n del Modelo")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info(f"**Sensor:** {config['sensor_id']}")
        st.info(f"**Arquitectura:** {MODEL_CONFIGS[config['model_type']]['name']}")
    with col2:
        st.info(f"**Caracter√≠sticas:** {len(config['features'])}")
        if 'training_config' in config:
            tc = config['training_config']
            st.info(f"**Learning Rate:** {tc['learning_rate']}")
    with col3:
        if 'training_config' in config:
            tc = config['training_config']
            st.info(f"**√âpocas m√°x:** {tc['epochs']}")
            st.info(f"**Batch Size:** {tc['batch_size']}")


def show_complete_model_results(metrics, history, test_data, config, title="Resultados del Modelo Bayesiano"):
    """Funci√≥n reutilizable para mostrar resultados completos del modelo."""
    st.header(f" {title}")
    
    # Mostrar configuraci√≥n del modelo
    show_model_configuration_summary(config)
    
    # Mostrar m√©tricas
    show_model_metrics(metrics)
    
    # Mostrar historia del entrenamiento
    st.subheader("üìà Historia del Entrenamiento")
    show_training_history(history)
    
    # Mostrar predicciones con incertidumbre
    show_uncertainty_predictions(test_data, metrics)
    
    # An√°lisis de incertidumbre
    st.subheader("üîç An√°lisis de Incertidumbre")
    show_uncertainty_histogram(metrics)
